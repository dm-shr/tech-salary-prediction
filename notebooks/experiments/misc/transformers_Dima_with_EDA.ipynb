{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single bert tiny\n",
    "# 486.6s\t79\tEpoch 1/10, Train Loss: 4.5435, Test Loss: 0.4326, Train R2: -10.4119, Test R2: -0.0972\n",
    "# 903.8s\t80\tEpoch 2/10, Train Loss: 0.3370, Test Loss: 0.3351, Train R2: 0.1541, Test R2: 0.1500\n",
    "# 1321.1s\t81\tEpoch 3/10, Train Loss: 0.2568, Test Loss: 0.2575, Train R2: 0.3552, Test R2: 0.3467\n",
    "# 1738.9s\t82\tEpoch 4/10, Train Loss: 0.1917, Test Loss: 0.2161, Train R2: 0.5191, Test R2: 0.4517\n",
    "# 2156.3s\t83\tEpoch 5/10, Train Loss: 0.1646, Test Loss: 0.1717, Train R2: 0.5868, Test R2: 0.5643\n",
    "# 2573.7s\t84\tEpoch 6/10, Train Loss: 0.1491, Test Loss: 0.1417, Train R2: 0.6258, Test R2: 0.6405\n",
    "# 2991.3s\t85\tEpoch 7/10, Train Loss: 0.1374, Test Loss: 0.1543, Train R2: 0.6550, Test R2: 0.6086\n",
    "# 3408.8s\t86\tEpoch 8/10, Train Loss: 0.1299, Test Loss: 0.1488, Train R2: 0.6739, Test R2: 0.6226\n",
    "# 3826.4s\t87\tEpoch 9/10, Train Loss: 0.1241, Test Loss: 0.1491, Train R2: 0.6884, Test R2: 0.6217\n",
    "\n",
    "# double bert tiny mse loss - new dataframe\n",
    "# Epoch 1/10, Train Loss: 3.8994, Test Loss: 0.4146, Train R2: -8.7940, Test R2: -0.0517\n",
    "\n",
    "# double bert tiny mse loss\n",
    "# 507.9s\t37\tEpoch 1/10, Train Loss: 3.8773, Test Loss: 0.4104, Train R2: -8.7386, Test R2: -0.0409\n",
    "# 939.0s\t38\tEpoch 2/10, Train Loss: 0.3164, Test Loss: 0.2925, Train R2: 0.2059, Test R2: 0.2578\n",
    "# 1370.5s\t39\tEpoch 3/10, Train Loss: 0.2254, Test Loss: 0.2519, Train R2: 0.4341, Test R2: 0.3608\n",
    "# 1801.6s\t40\tEpoch 4/10, Train Loss: 0.1742, Test Loss: 0.1956, Train R2: 0.5629, Test R2: 0.5038\n",
    "# 2232.6s\t41\tEpoch 5/10, Train Loss: 0.1508, Test Loss: 0.1705, Train R2: 0.6214, Test R2: 0.5673\n",
    "# 2663.8s\t42\tEpoch 6/10, Train Loss: 0.1379, Test Loss: 0.1410, Train R2: 0.6539, Test R2: 0.6423\n",
    "# 3094.7s\t43\tEpoch 7/10, Train Loss: 0.1279, Test Loss: 0.1533, Train R2: 0.6788, Test R2: 0.6111\n",
    "\n",
    "# double bert tiny. huber loss\n",
    "# Epoch 1/10, Train Loss: 0.9089, Test Loss: 0.1598, Train R2: -8.1284, Test R2: 0.1700\n",
    "# Starting training...\n",
    "# Epoch done, evaluating...\n",
    "# Epoch 2/10, Train Loss: 0.1170, Test Loss: 0.1208, Train R2: 0.4008, Test R2: 0.3756\n",
    "# Starting training...\n",
    "# Epoch done, evaluating...\n",
    "# Epoch 3/10, Train Loss: 0.0834, Test Loss: 0.0991, Train R2: 0.5746, Test R2: 0.4910\n",
    "# Starting training...\n",
    "# Epoch done, evaluating...\n",
    "# Epoch 4/10, Train Loss: 0.0715, Test Loss: 0.0801, Train R2: 0.6356, Test R2: 0.5895\n",
    "# Starting training...\n",
    "# Epoch done, evaluating...\n",
    "# Epoch 5/10, Train Loss: 0.0659, Test Loss: 0.0785, Train R2: 0.6651, Test R2: 0.5978\n",
    "# Starting training...\n",
    "# Epoch done, evaluating...\n",
    "# Epoch 6/10, Train Loss: 0.0618, Test Loss: 0.0671, Train R2: 0.6858, Test R2: 0.6570\n",
    "# Starting training...\n",
    "# Epoch done, evaluating...\n",
    "# Epoch 7/10, Train Loss: 0.0580, Test Loss: 0.0741, Train R2: 0.7049, Test R2: 0.6208\n",
    "# Starting training...\n",
    "# Epoch done, evaluating...\n",
    "# Epoch 8/10, Train Loss: 0.0553, Test Loss: 0.0708, Train R2: 0.7188, Test R2: 0.6376\n",
    "# Starting training...\n",
    "# Epoch done, evaluating...\n",
    "# Epoch 9/10, Train Loss: 0.0525, Test Loss: 0.0684, Train R2: 0.7335, Test R2: 0.6502\n",
    "# Starting training...\n",
    "# Epoch done, evaluating...\n",
    "# Epoch 10/10, Train Loss: 0.0505, Test Loss: 0.0720, Train R2: 0.7437, Test R2: 0.6318\n",
    "\n",
    "# double bert tiny. huber loss. mean pooling\n",
    "# 532.0s\t35\tEpoch 1/10, Train Loss: 0.8594, Test Loss: 0.1773, Train R2: -7.2734, Test R2: 0.0785\n",
    "# 968.6s\t36\tEpoch 2/10, Train Loss: 0.1289, Test Loss: 0.1205, Train R2: 0.3397, Test R2: 0.3748\n",
    "# 1406.0s\t37\tEpoch 3/10, Train Loss: 0.0860, Test Loss: 0.1074, Train R2: 0.5603, Test R2: 0.4463\n",
    "# 1843.5s\t38\tEpoch 4/10, Train Loss: 0.0711, Test Loss: 0.0856, Train R2: 0.6381, Test R2: 0.5609\n",
    "# 2280.8s\t39\tEpoch 5/10, Train Loss: 0.0640, Test Loss: 0.0768, Train R2: 0.6742, Test R2: 0.6068\n",
    "# 2718.3s\t40\tEpoch 6/10, Train Loss: 0.0597, Test Loss: 0.0690, Train R2: 0.6964, Test R2: 0.6472\n",
    "# 3155.8s\t41\tEpoch 7/10, Train Loss: 0.0561, Test Loss: 0.0751, Train R2: 0.7145, Test R2: 0.6155\n",
    "\n",
    "# double bert tiny. huber loss. regression on mask token prompt v1:\n",
    "# prompt = \"\"\"\\\n",
    "# Далее указано описание вакансии.\\\n",
    "# По шкале 1 (очень мало) до 100 (очень много) на этой позиции платят [MASK] рублей.[SEP]\n",
    "# \"\"\"\n",
    "\n",
    "# tsdae 10% train full descriptions (~2000)\n",
    "# Epoch 1/10, Train Loss: 0.8070, Test Loss: 0.2089, Train R2: -6.4429, Test R2: -0.0934\n",
    "# Starting training...\n",
    "# Epoch done, evaluating...\n",
    "# Epoch 2/10, Train Loss: 0.1387, Test Loss: 0.1438, Train R2: 0.2898, Test R2: 0.2516\n",
    "# Starting training...\n",
    "# Epoch done, evaluating...\n",
    "# Epoch 3/10, Train Loss: 0.1007, Test Loss: 0.1044, Train R2: 0.4861, Test R2: 0.4624\n",
    "# Starting training...\n",
    "# Epoch done, evaluating...\n",
    "# Epoch 4/10, Train Loss: 0.0848, Test Loss: 0.1130, Train R2: 0.5728, Test R2: 0.4187\n",
    "# Starting training...\n",
    "# Epoch done, evaluating...\n",
    "# Epoch 5/10, Train Loss: 0.0760, Test Loss: 0.0912, Train R2: 0.6137, Test R2: 0.5321\n",
    "# Starting training...\n",
    "# Epoch done, evaluating...\n",
    "# Epoch 6/10, Train Loss: 0.0689, Test Loss: 0.0740, Train R2: 0.6495, Test R2: 0.6212\n",
    "# Starting training...\n",
    "# Epoch done, evaluating...\n",
    "# Epoch 7/10, Train Loss: 0.0661, Test Loss: 0.0876, Train R2: 0.6643, Test R2: 0.5511\n",
    "# Starting training...\n",
    "# Epoch done, evaluating...\n",
    "# Epoch 8/10, Train Loss: 0.0623, Test Loss: 0.0743, Train R2: 0.6846, Test R2: 0.6200\n",
    "# Starting training...\n",
    "# Epoch done, evaluating...\n",
    "# Epoch 9/10, Train Loss: 0.0582, Test Loss: 0.0797, Train R2: 0.7047, Test R2: 0.5924\n",
    "# Starting training...\n",
    "# Epoch done, evaluating...\n",
    "# Epoch 10/10, Train Loss: 0.0559, Test Loss: 0.0778, Train R2: 0.7172, Test R2: 0.6021\n",
    "\n",
    "\n",
    "# tsdae 5% train full descriptions (~400)\n",
    "# Epoch 1/10, Train Loss: 0.8010, Test Loss: 0.1868, Train R2: -6.3226, Test R2: 0.0272\n",
    "# Starting training...\n",
    "# Epoch done, evaluating...\n",
    "# Epoch 2/10, Train Loss: 0.1374, Test Loss: 0.1394, Train R2: 0.2941, Test R2: 0.2760\n",
    "# Starting training...\n",
    "# Epoch done, evaluating...\n",
    "# Epoch 3/10, Train Loss: 0.0982, Test Loss: 0.0885, Train R2: 0.4971, Test R2: 0.5459\n",
    "# Starting training...\n",
    "# Epoch done, evaluating...\n",
    "# Epoch 4/10, Train Loss: 0.0810, Test Loss: 0.0871, Train R2: 0.5871, Test R2: 0.5534\n",
    "# Starting training...\n",
    "# Epoch done, evaluating...\n",
    "# Epoch 5/10, Train Loss: 0.0730, Test Loss: 0.0731, Train R2: 0.6278, Test R2: 0.6260\n",
    "# Starting training...\n",
    "# Epoch done, evaluating...\n",
    "# Epoch 6/10, Train Loss: 0.0677, Test Loss: 0.0745, Train R2: 0.6553, Test R2: 0.6184\n",
    "# Starting training...\n",
    "# Epoch done, evaluating...\n",
    "# Epoch 7/10, Train Loss: 0.0629, Test Loss: 0.0760, Train R2: 0.6800, Test R2: 0.6107\n",
    "# Starting training...\n",
    "# Epoch done, evaluating...\n",
    "# Epoch 8/10, Train Loss: 0.0598, Test Loss: 0.0685, Train R2: 0.6954, Test R2: 0.6498\n",
    "# Starting training...\n",
    "# Epoch done, evaluating...\n",
    "# Epoch 9/10, Train Loss: 0.0565, Test Loss: 0.0773, Train R2: 0.7128, Test R2: 0.6042\n",
    "# Starting training...\n",
    "# Epoch done, evaluating...\n",
    "# Epoch 10/10, Train Loss: 0.0543, Test Loss: 0.0710, Train R2: 0.7241, Test R2: 0.6371\n",
    "\n",
    "# tsdae 1% train full descriptions (~100)\n",
    "# Epoch 9/10, Train Loss: 0.0543, Test Loss: 0.0610, Train R2: 0.7247, Test R2: 0.6878\n",
    "\n",
    "# tsdae 5% train 30-60w sentences (~1000)\n",
    "# Epoch 8/10, Train Loss: 0.0600, Test Loss: 0.0657, Train R2: 0.6945, Test R2: 0.6642, Test R2 with catboost: 0.7302\n",
    "\n",
    "# tsdae 1% train 10-60w sentences (~1000)\n",
    "# Epoch 1/10, Train Loss: 0.8169, Test Loss: 0.1824, Train R2: -6.7389, Test R2: 0.0507, Test R2 with catboost: 0.5293\n",
    "# Starting training...\n",
    "# Epoch done, evaluating...\n",
    "# Epoch 2/10, Train Loss: 0.1365, Test Loss: 0.1263, Train R2: 0.2982, Test R2: 0.3444, Test R2 with catboost: 0.6240\n",
    "# Starting training...\n",
    "# Epoch done, evaluating...\n",
    "# Epoch 3/10, Train Loss: 0.0937, Test Loss: 0.0899, Train R2: 0.5211, Test R2: 0.5377, Test R2 with catboost: 0.6825\n",
    "# Starting training...\n",
    "# Epoch done, evaluating...\n",
    "# Epoch 4/10, Train Loss: 0.0795, Test Loss: 0.0743, Train R2: 0.5942, Test R2: 0.6194, Test R2 with catboost: 0.7098\n",
    "# Starting training...\n",
    "# Epoch done, evaluating...\n",
    "# Epoch 5/10, Train Loss: 0.0714, Test Loss: 0.0805, Train R2: 0.6370, Test R2: 0.5875, Test R2 with catboost: 0.7067\n",
    "# Starting training...\n",
    "# Epoch done, evaluating...\n",
    "# Epoch 6/10, Train Loss: 0.0660, Test Loss: 0.0758, Train R2: 0.6640, Test R2: 0.6118, Test R2 with catboost: 0.7153\n",
    "# Starting training...\n",
    "# Epoch done, evaluating...\n",
    "# Epoch 7/10, Train Loss: 0.0618, Test Loss: 0.0756, Train R2: 0.6852, Test R2: 0.6131, Test R2 with catboost: 0.7175\n",
    "# Starting training...\n",
    "# Epoch done, evaluating...\n",
    "# Epoch 8/10, Train Loss: 0.0583, Test Loss: 0.0612, Train R2: 0.7036, Test R2: 0.6870, Test R2 with catboost: 0.7374\n",
    "# Starting training...\n",
    "# Epoch done, evaluating...\n",
    "# Epoch 9/10, Train Loss: 0.0559, Test Loss: 0.0617, Train R2: 0.7158, Test R2: 0.6846, Test R2 with catboost: 0.7379\n",
    "# Starting training...\n",
    "# Epoch done, evaluating...\n",
    "# Epoch 10/10, Train Loss: 0.0527, Test Loss: 0.0654, Train R2: 0.7327, Test R2: 0.6655, Test R2 with catboost: 0.7365\n",
    "\n",
    "\n",
    "# tsdae 0.05% train full descriptions (~50)\n",
    "# Epoch 1/10, Train Loss: 0.8807, Test Loss: 0.1641, Train R2: -7.6731, Test R2: 0.1473, Test R2 with catboost: 0.5561\n",
    "# Starting training...\n",
    "# Epoch done, evaluating...\n",
    "# Epoch 2/10, Train Loss: 0.1287, Test Loss: 0.1094, Train R2: 0.3404, Test R2: 0.4349, Test R2 with catboost: 0.6477\n",
    "# Starting training...\n",
    "# Epoch done, evaluating...\n",
    "# Epoch 3/10, Train Loss: 0.0892, Test Loss: 0.0970, Train R2: 0.5445, Test R2: 0.5010, Test R2 with catboost: 0.6746\n",
    "# Starting training...\n",
    "# Epoch done, evaluating...\n",
    "# Epoch 4/10, Train Loss: 0.0738, Test Loss: 0.0820, Train R2: 0.6244, Test R2: 0.5797, Test R2 with catboost: 0.6997\n",
    "# Starting training...\n",
    "# Epoch done, evaluating...\n",
    "# Epoch 5/10, Train Loss: 0.0667, Test Loss: 0.0722, Train R2: 0.6607, Test R2: 0.6302, Test R2 with catboost: 0.7163\n",
    "# Starting training...\n",
    "# Epoch done, evaluating...\n",
    "# Epoch 6/10, Train Loss: 0.0627, Test Loss: 0.0723, Train R2: 0.6813, Test R2: 0.6299, Test R2 with catboost: 0.7182\n",
    "# Starting training...\n",
    "# Epoch done, evaluating...\n",
    "# Epoch 7/10, Train Loss: 0.0589, Test Loss: 0.0858, Train R2: 0.7011, Test R2: 0.5606, Test R2 with catboost: 0.7048\n",
    "# Starting training...\n",
    "# Epoch done, evaluating...\n",
    "# Epoch 8/10, Train Loss: 0.0559, Test Loss: 0.0720, Train R2: 0.7160, Test R2: 0.6314, Test R2 with catboost: 0.7220\n",
    "# Starting training...\n",
    "# Epoch done, evaluating...\n",
    "# Epoch 9/10, Train Loss: 0.0533, Test Loss: 0.0706, Train R2: 0.7291, Test R2: 0.6389, Test R2 with catboost: 0.7274\n",
    "# Starting training...\n",
    "# Epoch done, evaluating...\n",
    "# Epoch 10/10, Train Loss: 0.0506, Test Loss: 0.0734, Train R2: 0.7428, Test R2: 0.6245, Test R2 with catboost: 0.7249"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{42: {'double_huber': {'train_loss': [4.895582866668701, 4.82876033782959], 'test_loss': [5.025346279144287, 4.959561824798584], 'train_r2': [-126.75456492227305, -123.61191064445534], 'test_r2': [-305.98148364215854, -298.65034845118834], 'test_r2_with_catboost': [-308.3656244541365, -304.67466596184187], 'max_test_r2': -298.65034845118834, 'best_preds': [0.12027512, 0.11661099, 0.100861646, 0.13811573, 0.103326894, 0.1067706, 0.14346679, 0.1412911, 0.09676818, 0.08949141, 0.14478289, 0.092359975, 0.09914944, 0.09976987, 0.11786256, 0.13117395, 0.08234694, 0.10037506, 0.1298222, 0.08952253, 0.1075126, 0.09814962, 0.10840017, 0.07693586, 0.10175996, 0.08106599, 0.104638495, 0.092652805, 0.1320094, 0.120644875, 0.10984291, 0.110883795, 0.09372187, 0.1435063, 0.10443308, 0.10222577, 0.1324031, 0.080805294, 0.124112286, 0.101748995]}, 'double_huber_1p_descriptions_tsdae': {'train_loss': [4.926570320129395, 4.854640960693359], 'test_loss': [5.068599224090576, 4.993791818618774], 'train_r2': [-128.21837236524715, -124.85369649487428], 'test_r2': [-309.8074335854131, -301.45296566845934], 'test_r2_with_catboost': [-310.28132300999704, -306.08673623408373], 'max_test_r2': -301.45296566845934, 'best_preds': [0.12033311, 0.093177706, 0.05576992, 0.110883, 0.025653645, 0.07833716, 0.14282915, 0.09229412, 0.094399974, 0.09450123, 0.08987065, 0.11289308, 0.05975513, 0.115397565, 0.07055357, 0.11902479, 0.08384396, 0.08534874, 0.08337082, 0.06985984, 0.1110988, 0.071180984, 0.005290292, 0.12435942, 0.07420421, 0.04993099, 0.092471965, 0.08639342, 0.13584742, 0.12128252, 0.08832386, 0.093726404, 0.07880163, 0.07138027, -0.0014522821, 0.10028696, 0.09166123, 0.083297536, 0.038526896, 0.031884763]}}, 78687: {'double_huber': {'train_loss': [4.784414386749267, 4.725394439697266], 'test_loss': [4.959856271743774, 4.892046928405762], 'train_r2': [-125.12391358267728, -122.34189985463321], 'test_r2': [-281.6284276666995, -274.67922978418886], 'test_r2_with_catboost': [-288.711621261893, -285.18225194551974], 'max_test_r2': -274.67922978418886, 'best_preds': [0.18377161, 0.16023499, 0.22657028, 0.19048642, 0.16235167, 0.15793964, 0.19018333, 0.18734266, 0.16316113, 0.18447116, 0.25584885, 0.23342773, 0.17398143, 0.1796633, 0.21336094, 0.19822201, 0.20510891, 0.21905631, 0.21049345, 0.22966057, 0.23760924, 0.2425417, 0.2189199, 0.19046023, 0.22391412, 0.21187446, 0.2198726, 0.22012722, 0.19125839, 0.17459404, 0.2393212, 0.21124294, 0.19984141, 0.23034874, 0.17663988, 0.22283193, 0.19604814, 0.2319521, 0.21066761, 0.22719043]}, 'double_huber_1p_descriptions_tsdae': {'train_loss': [4.912404346466064, 4.835915374755859], 'test_loss': [5.104062557220459, 5.029770374298096], 'train_r2': [-131.2488744000358, -127.55417489903576], 'test_r2': [-295.59091694058, -287.7881638435749], 'test_r2_with_catboost': [-295.73632878504026, -291.82089155203687], 'max_test_r2': -287.7881638435749, 'best_preds': [0.09591783, 0.0895936, 0.059203073, 0.08890428, 0.05627701, 0.013340071, 0.071029216, 0.063968636, 0.0820201, 0.056070212, 0.115649454, 0.10247173, 0.055726957, 0.04528532, 0.077618346, 0.17623931, 0.08828846, 0.099613085, 0.07165534, 0.099361785, 0.13599685, 0.09752524, 0.08967613, 0.045633946, 0.102433376, 0.105126835, 0.08840738, 0.08457071, 0.059713304, 0.07779862, 0.103939906, 0.05012542, 0.033787765, 0.081166245, 0.056878842, 0.0050263517, 0.09586714, 0.078818284, 0.053122483, 0.051753655]}}, 123123: {'double_huber': {'train_loss': [4.868027687072754, 4.784506702423096], 'test_loss': [4.750050783157349, 4.6618523597717285], 'train_r2': [-163.64960400154607, -158.62225327525206], 'test_r2': [-83.56680638062407, -80.76182768260286], 'test_r2_with_catboost': [-85.87791959896046, -84.45008372083883], 'max_test_r2': -80.76182768260286, 'best_preds': [0.1546982, 0.21822983, 0.27903712, 0.28271, 0.27470863, 0.1949315, 0.15777266, 0.23991942, 0.25332955, 0.18813553, 0.19930393, 0.20250201, 0.26269954, 0.25513524, 0.2129252, 0.21325177, 0.21550167, 0.18755409, 0.26334584, 0.16519907, 0.23612115, 0.22739318, 0.20515046, 0.27077967, 0.16430885, 0.32951272, 0.24992278, 0.19844201, 0.21328264, 0.25391936, 0.3158098, 0.28197387, 0.23665676, 0.23451838, 0.23758736, 0.17630723, 0.20274079, 0.2167333, 0.27307644, 0.21966729]}, 'double_huber_1p_descriptions_tsdae': {'train_loss': [4.980844879150391, 4.909105491638184], 'test_loss': [4.869690418243408, 4.796004056930542], 'train_r2': [-170.63576907499117, -166.2027507810213], 'test_r2': [-87.53656460748684, -85.11733410820567], 'test_r2_with_catboost': [-87.87825155597056, -86.66200437845097], 'max_test_r2': -85.11733410820567, 'best_preds': [0.13330302, 0.07826625, 0.1040707, 0.09656498, 0.06378722, 0.17945048, 0.07813131, 0.046231844, 0.08918338, 0.122884035, 0.08037147, 0.12904993, 0.08478657, 0.1213435, 0.13904424, 0.08569347, 0.10350867, 0.13872522, 0.098869964, 0.13211048, 0.07525019, 0.09604506, 0.09539081, 0.037656013, 0.040421087, 0.15152234, 0.08215582, 0.062414035, 0.09221783, 0.042863827, 0.10770321, 0.09650466, 0.08681671, 0.10570925, 0.072442986, 0.061906703, 0.071915686, 0.07336294, 0.13587224, 0.11333297]}}}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import json\n",
    "\n",
    "history_path = '../models/combined_history.pickle'\n",
    "with open(history_path, 'rb') as f:\n",
    "    history = pickle.load(f)\n",
    "    print(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Grouped DataFrame with Mean and Std:\n",
      "                       experiment_name  epoch  train_loss_count  \\\n",
      "0                         double_huber      1                 3   \n",
      "1                         double_huber      2                 3   \n",
      "2                         double_huber      3                 3   \n",
      "3                         double_huber      4                 3   \n",
      "4                         double_huber      5                 3   \n",
      "5                         double_huber      6                 3   \n",
      "6                         double_huber      7                 3   \n",
      "7                         double_huber      8                 3   \n",
      "8                         double_huber      9                 3   \n",
      "9                         double_huber     10                 3   \n",
      "10  double_huber_1p_descriptions_tsdae      1                 3   \n",
      "11  double_huber_1p_descriptions_tsdae      2                 3   \n",
      "12  double_huber_1p_descriptions_tsdae      3                 3   \n",
      "13  double_huber_1p_descriptions_tsdae      4                 3   \n",
      "14  double_huber_1p_descriptions_tsdae      5                 3   \n",
      "15  double_huber_1p_descriptions_tsdae      6                 3   \n",
      "16  double_huber_1p_descriptions_tsdae      7                 3   \n",
      "17  double_huber_1p_descriptions_tsdae      8                 3   \n",
      "18  double_huber_1p_descriptions_tsdae      9                 3   \n",
      "19  double_huber_1p_descriptions_tsdae     10                 3   \n",
      "\n",
      "    train_loss_mean  train_loss_std  test_loss_mean  test_loss_std  \\\n",
      "0          0.852675        0.047382        0.147352       0.027232   \n",
      "1          0.109519        0.007008        0.105378       0.011262   \n",
      "2          0.083798        0.000394        0.085969       0.009613   \n",
      "3          0.072204        0.000633        0.083277       0.009545   \n",
      "4          0.066078        0.000445        0.073793       0.007550   \n",
      "5          0.061955        0.000456        0.069847       0.002531   \n",
      "6          0.058787        0.000704        0.071309       0.003520   \n",
      "7          0.055799        0.000712        0.067740       0.004679   \n",
      "8          0.053213        0.000732        0.072858       0.008465   \n",
      "9          0.050706        0.000455        0.067051       0.001589   \n",
      "10         0.838310        0.024735        0.174657       0.015481   \n",
      "11         0.128968        0.004152        0.106961       0.016231   \n",
      "12         0.092089        0.001835        0.089162       0.009094   \n",
      "13         0.077907        0.001154        0.075820       0.008466   \n",
      "14         0.069198        0.000518        0.075820       0.007608   \n",
      "15         0.063871        0.000547        0.071667       0.006498   \n",
      "16         0.060279        0.000461        0.064470       0.003004   \n",
      "17         0.057088        0.000144        0.066857       0.004011   \n",
      "18         0.054393        0.000045        0.065499       0.003128   \n",
      "19         0.051895        0.000371        0.067569       0.008842   \n",
      "\n",
      "    train_r2_mean  train_r2_std  test_r2_mean  test_r2_std  \\\n",
      "0       -7.468598      0.602944      0.234061     0.144321   \n",
      "1        0.438665      0.036028      0.455161     0.057003   \n",
      "2        0.572355      0.002377      0.558314     0.048593   \n",
      "3        0.632699      0.003068      0.572727     0.048831   \n",
      "4        0.663940      0.002342      0.621934     0.037758   \n",
      "5        0.685009      0.002477      0.642430     0.012738   \n",
      "6        0.701019      0.003717      0.634964     0.017073   \n",
      "7        0.716330      0.003537      0.653378     0.024279   \n",
      "8        0.729759      0.003854      0.627189     0.043159   \n",
      "9        0.742412      0.002147      0.657038     0.007839   \n",
      "10      -6.998466      0.370850      0.094220     0.081456   \n",
      "11       0.338857      0.020888      0.446479     0.085295   \n",
      "12       0.529365      0.009643      0.541338     0.046239   \n",
      "13       0.604755      0.007719      0.611215     0.044173   \n",
      "14       0.647783      0.002956      0.611520     0.040152   \n",
      "15       0.675513      0.002297      0.633283     0.033369   \n",
      "16       0.693567      0.002717      0.670441     0.014716   \n",
      "17       0.710015      0.001057      0.658119     0.019966   \n",
      "18       0.723363      0.000336      0.665164     0.016673   \n",
      "19       0.736334      0.001705      0.654593     0.044813   \n",
      "\n",
      "    test_r2_with_catboost_mean  test_r2_with_catboost_std  test_r2_ci_low  \\\n",
      "0                     0.585624                   0.041936       -0.124451   \n",
      "1                     0.657250                   0.017071        0.313557   \n",
      "2                     0.691966                   0.014703        0.437602   \n",
      "3                     0.700353                   0.015238        0.451424   \n",
      "4                     0.715774                   0.011107        0.528137   \n",
      "5                     0.724151                   0.005325        0.610787   \n",
      "6                     0.723605                   0.006034        0.592552   \n",
      "7                     0.730858                   0.007448        0.593067   \n",
      "8                     0.725648                   0.012877        0.519975   \n",
      "9                     0.734635                   0.003439        0.637566   \n",
      "10                    0.542346                   0.022822       -0.108127   \n",
      "11                    0.650774                   0.021985        0.234593   \n",
      "12                    0.684128                   0.012306        0.426474   \n",
      "13                    0.708627                   0.012550        0.501484   \n",
      "14                    0.712970                   0.009661        0.511778   \n",
      "15                    0.721840                   0.008127        0.550390   \n",
      "16                    0.732182                   0.003993        0.633885   \n",
      "17                    0.731859                   0.004518        0.608520   \n",
      "18                    0.735741                   0.002917        0.623746   \n",
      "19                    0.733332                   0.011497        0.543270   \n",
      "\n",
      "    test_r2_ci_high  \n",
      "0          0.592573  \n",
      "1          0.596765  \n",
      "2          0.679026  \n",
      "3          0.694030  \n",
      "4          0.715731  \n",
      "5          0.674072  \n",
      "6          0.677376  \n",
      "7          0.713689  \n",
      "8          0.734404  \n",
      "9          0.676511  \n",
      "10         0.296568  \n",
      "11         0.658364  \n",
      "12         0.656201  \n",
      "13         0.720945  \n",
      "14         0.711263  \n",
      "15         0.716177  \n",
      "16         0.706996  \n",
      "17         0.707718  \n",
      "18         0.706582  \n",
      "19         0.765915  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "experiment_name                     epoch\n",
       "double_huber                        1        [0.06882417755686698, 0.29794449182117044, 0.3...\n",
       "                                    2        [0.4144525661461438, 0.5203087393439466, 0.430...\n",
       "                                    3        [0.5098219480939717, 0.6070072093616716, 0.558...\n",
       "                                    4        [0.5165861013846074, 0.6053402229135455, 0.596...\n",
       "                                    5        [0.6227555702653315, 0.6592754315348033, 0.583...\n",
       "                                    6        [0.6277275150120449, 0.6501593827028682, 0.649...\n",
       "                                    7        [0.635701462250618, 0.6516563837163661, 0.6175...\n",
       "                                    8        [0.6270229191958527, 0.6582782601352275, 0.674...\n",
       "                                    9        [0.5808750028670073, 0.6662830447677872, 0.634...\n",
       "                                    10       [0.6484680760734272, 0.6638447954581641, 0.658...\n",
       "double_huber_1p_descriptions_tsdae  1        [0.0977038244973345, 0.17387831325634495, 0.01...\n",
       "                                    2        [0.439189063142457, 0.5351850462061409, 0.3650...\n",
       "                                    3        [0.5246639792107852, 0.5936006953258188, 0.505...\n",
       "                                    4        [0.5683236820334877, 0.6087542196038705, 0.656...\n",
       "                                    5        [0.5925748124068141, 0.584346616716616, 0.6576...\n",
       "                                    6        [0.6687730217212884, 0.6285337118951773, 0.602...\n",
       "                                    7        [0.6776926240685032, 0.680122621331148, 0.6535...\n",
       "                                    8        [0.6741613850267089, 0.6644377164237134, 0.635...\n",
       "                                    9        [0.6825888519300998, 0.6493610913430046, 0.663...\n",
       "                                    10       [0.6171150380024097, 0.7042313833864224, 0.642...\n",
       "Name: test_r2, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import pickle\n",
    "\n",
    "combined_history_path = '../data/kagglenb/models/combined_history.pickle'\n",
    "with open(combined_history_path, 'rb') as f:\n",
    "    combined_history = pickle.load(f)\n",
    "\n",
    "# Initialize an empty list to store the rows\n",
    "rows = []\n",
    "\n",
    "# Iterate through the dictionary\n",
    "for seed, experiments in combined_history.items():\n",
    "    for experiment_name, metrics in experiments.items():\n",
    "        num_epochs = len(metrics['train_loss'])\n",
    "        for epoch in range(num_epochs):\n",
    "            row = {\n",
    "                'random_seed': seed,\n",
    "                'experiment_name': experiment_name,\n",
    "                'epoch': epoch + 1,\n",
    "                'train_loss': metrics['train_loss'][epoch],\n",
    "                'test_loss': metrics['test_loss'][epoch],\n",
    "                'train_r2': metrics['train_r2'][epoch],\n",
    "                'test_r2': metrics['test_r2'][epoch],\n",
    "                'test_r2_with_catboost': metrics['test_r2_with_catboost'][epoch]\n",
    "            }\n",
    "            rows.append(row)\n",
    "\n",
    "# Convert the list of rows into a DataFrame\n",
    "history = pd.DataFrame(rows)\n",
    "\n",
    "# # Display the DataFrame\n",
    "# print(history)\n",
    "\n",
    "# Group by experiment name and epoch, then calculate mean and std\n",
    "grouped_history = history.groupby(['experiment_name', 'epoch']).agg(\n",
    "    train_loss_count=('train_loss', 'count'),\n",
    "    train_loss_mean=('train_loss', 'mean'),\n",
    "    train_loss_std=('train_loss', 'std'),\n",
    "    test_loss_mean=('test_loss', 'mean'),\n",
    "    test_loss_std=('test_loss', 'std'),\n",
    "    train_r2_mean=('train_r2', 'mean'),\n",
    "    train_r2_std=('train_r2', 'std'),\n",
    "    test_r2_mean=('test_r2', 'mean'),\n",
    "    test_r2_std=('test_r2', 'std'),\n",
    "    test_r2_with_catboost_mean=('test_r2_with_catboost', 'mean'),\n",
    "    test_r2_with_catboost_std=('test_r2_with_catboost', 'std')\n",
    ").reset_index()\n",
    "\n",
    "t_value = stats.t.ppf(0.975, grouped_history['train_loss_count'] - 1)  # 0.975 corresponds to (1 - alpha/2)\n",
    "# Calculate the margin of error\n",
    "me = t_value * grouped_history['test_r2_std'] / (grouped_history['train_loss_count'] ** 0.5)\n",
    "# Calculate the lower and upper bounds of the confidence interval   \n",
    "grouped_history['test_r2_ci_low'] = grouped_history['test_r2_mean'] - me \n",
    "grouped_history['test_r2_ci_high'] = grouped_history['test_r2_mean'] + me \n",
    "\n",
    "# Display the grouped DataFrame\n",
    "print(\"\\nGrouped DataFrame with Mean and Std:\")\n",
    "print(grouped_history)\n",
    "\n",
    "# for each experiment and epoch, get arrray of test r2 values\n",
    "test_r2 = history.groupby(['experiment_name', 'epoch'])['test_r2'].apply(list)\n",
    "test_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  experiment_name  epoch  train_loss_count  train_loss_mean  train_loss_std  \\\n",
      "0    double_huber      1                 3         0.852675        0.047382   \n",
      "1    double_huber      2                 3         0.109519        0.007008   \n",
      "2    double_huber      3                 3         0.083798        0.000394   \n",
      "3    double_huber      4                 3         0.072204        0.000633   \n",
      "4    double_huber      5                 3         0.066078        0.000445   \n",
      "5    double_huber      6                 3         0.061955        0.000456   \n",
      "6    double_huber      7                 3         0.058787        0.000704   \n",
      "7    double_huber      8                 3         0.055799        0.000712   \n",
      "8    double_huber      9                 3         0.053213        0.000732   \n",
      "9    double_huber     10                 3         0.050706        0.000455   \n",
      "\n",
      "   test_loss_mean  test_loss_std  train_r2_mean  train_r2_std  test_r2_mean  \\\n",
      "0        0.147352       0.027232      -7.468598      0.602944      0.234061   \n",
      "1        0.105378       0.011262       0.438665      0.036028      0.455161   \n",
      "2        0.085969       0.009613       0.572355      0.002377      0.558314   \n",
      "3        0.083277       0.009545       0.632699      0.003068      0.572727   \n",
      "4        0.073793       0.007550       0.663940      0.002342      0.621934   \n",
      "5        0.069847       0.002531       0.685009      0.002477      0.642430   \n",
      "6        0.071309       0.003520       0.701019      0.003717      0.634964   \n",
      "7        0.067740       0.004679       0.716330      0.003537      0.653378   \n",
      "8        0.072858       0.008465       0.729759      0.003854      0.627189   \n",
      "9        0.067051       0.001589       0.742412      0.002147      0.657038   \n",
      "\n",
      "   test_r2_std  test_r2_with_catboost_mean  test_r2_with_catboost_std  \\\n",
      "0     0.144321                    0.585624                   0.041936   \n",
      "1     0.057003                    0.657250                   0.017071   \n",
      "2     0.048593                    0.691966                   0.014703   \n",
      "3     0.048831                    0.700353                   0.015238   \n",
      "4     0.037758                    0.715774                   0.011107   \n",
      "5     0.012738                    0.724151                   0.005325   \n",
      "6     0.017073                    0.723605                   0.006034   \n",
      "7     0.024279                    0.730858                   0.007448   \n",
      "8     0.043159                    0.725648                   0.012877   \n",
      "9     0.007839                    0.734635                   0.003439   \n",
      "\n",
      "   test_r2_ci_low  test_r2_ci_high  \n",
      "0       -0.124451         0.592573  \n",
      "1        0.313557         0.596765  \n",
      "2        0.437602         0.679026  \n",
      "3        0.451424         0.694030  \n",
      "4        0.528137         0.715731  \n",
      "5        0.610787         0.674072  \n",
      "6        0.592552         0.677376  \n",
      "7        0.593067         0.713689  \n",
      "8        0.519975         0.734404  \n",
      "9        0.637566         0.676511  \n"
     ]
    }
   ],
   "source": [
    "print(grouped_history[grouped_history.experiment_name == 'double_huber'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Grouped DataFrame with Mean and Std:\n",
      "                    experiment_name  epoch  train_loss_mean  train_loss_std  \\\n",
      "0   double_huber_1p_sentences_tsdae      1         0.817044        0.015063   \n",
      "1   double_huber_1p_sentences_tsdae      2         0.129334        0.004032   \n",
      "2   double_huber_1p_sentences_tsdae      3         0.093455        0.000761   \n",
      "3   double_huber_1p_sentences_tsdae      4         0.079094        0.000286   \n",
      "4   double_huber_1p_sentences_tsdae      5         0.070632        0.000351   \n",
      "5   double_huber_1p_sentences_tsdae      6         0.065379        0.000553   \n",
      "6   double_huber_1p_sentences_tsdae      7         0.061618        0.000198   \n",
      "7   double_huber_1p_sentences_tsdae      8         0.058474        0.000222   \n",
      "8   double_huber_1p_sentences_tsdae      9         0.055727        0.000094   \n",
      "9   double_huber_1p_sentences_tsdae     10         0.053095        0.000465   \n",
      "10                       double_mse      1         3.602286        0.246520   \n",
      "11                       double_mse      2         0.287730        0.025902   \n",
      "12                       double_mse      3         0.210817        0.011338   \n",
      "13                       double_mse      4         0.172179        0.002296   \n",
      "14                       double_mse      5         0.150302        0.000166   \n",
      "15                       double_mse      6         0.137437        0.000770   \n",
      "16                       double_mse      7         0.129212        0.001515   \n",
      "17                       double_mse      8         0.122002        0.001226   \n",
      "18                       double_mse      9         0.116033        0.001676   \n",
      "19                       double_mse     10         0.110360        0.001140   \n",
      "\n",
      "    test_loss_mean  test_loss_std  train_r2_mean  train_r2_std  test_r2_mean  \\\n",
      "0         0.178733       0.021314      -6.685898      0.165144      0.072031   \n",
      "1         0.109221       0.016509       0.336111      0.021502      0.434020   \n",
      "2         0.092475       0.012088       0.522296      0.003927      0.523895   \n",
      "3         0.078457       0.011423       0.599139      0.001967      0.597730   \n",
      "4         0.076553       0.007171       0.640635      0.002105      0.607878   \n",
      "5         0.070728       0.005250       0.667967      0.002513      0.638257   \n",
      "6         0.064320       0.002949       0.687049      0.000710      0.671347   \n",
      "7         0.065937       0.003168       0.702862      0.001377      0.662980   \n",
      "8         0.064271       0.000601       0.716686      0.000781      0.671599   \n",
      "9         0.066744       0.009077       0.730370      0.002323      0.659017   \n",
      "10        0.388043       0.024839      -8.052403      0.615276      0.017715   \n",
      "11        0.269893       0.043408       0.277358      0.064628      0.316671   \n",
      "12        0.226581       0.028730       0.470509      0.028256      0.426347   \n",
      "13        0.184026       0.023014       0.567682      0.005585      0.534076   \n",
      "14        0.162900       0.015767       0.622613      0.000770      0.587607   \n",
      "15        0.149291       0.004948       0.654780      0.002065      0.622044   \n",
      "16        0.151042       0.006283       0.675420      0.003882      0.617626   \n",
      "17        0.141664       0.008281       0.693560      0.003178      0.641335   \n",
      "18        0.150554       0.018130       0.708587      0.004383      0.618808   \n",
      "19        0.140700       0.004309       0.722811      0.003006      0.643790   \n",
      "\n",
      "    test_r2_std  test_r2_with_catboost_mean  test_r2_with_catboost_std  \n",
      "0      0.113110                    0.536628                   0.032457  \n",
      "1      0.087624                    0.646734                   0.023369  \n",
      "2      0.062597                    0.679203                   0.017558  \n",
      "3      0.059212                    0.704769                   0.016342  \n",
      "4      0.037264                    0.711575                   0.009344  \n",
      "5      0.026567                    0.722245                   0.006699  \n",
      "6      0.014699                    0.731455                   0.004354  \n",
      "7      0.015566                    0.732376                   0.004258  \n",
      "8      0.003469                    0.736450                   0.002018  \n",
      "9      0.046388                    0.733915                   0.011896  \n",
      "10     0.064724                    0.525410                   0.020059  \n",
      "11     0.111320                    0.612229                   0.034048  \n",
      "12     0.073893                    0.650552                   0.021498  \n",
      "13     0.059215                    0.684670                   0.017442  \n",
      "14     0.039956                    0.703380                   0.012652  \n",
      "15     0.013129                    0.716035                   0.004959  \n",
      "16     0.016058                    0.716359                   0.006838  \n",
      "17     0.021543                    0.725070                   0.006597  \n",
      "18     0.046646                    0.720891                   0.013833  \n",
      "19     0.011582                    0.728814                   0.004528  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "experiment_name                  epoch\n",
       "double_huber_1p_sentences_tsdae  1        [0.024577297072122306, 0.20113826767431853, -0...\n",
       "                                 2        [0.40796329501068374, 0.5317161054795225, 0.36...\n",
       "                                 3        [0.48274626213949334, 0.5959326150190731, 0.49...\n",
       "                                 4        [0.5326604966814704, 0.6120828974922136, 0.648...\n",
       "                                 5        [0.5744837416090678, 0.6010762409755133, 0.648...\n",
       "                                 6        [0.6548479465504374, 0.6523070123164394, 0.607...\n",
       "                                 7        [0.6740372355810065, 0.6845155083855777, 0.655...\n",
       "                                 8        [0.6651671149267049, 0.6773375603983581, 0.646...\n",
       "                                 9        [0.6691442601368656, 0.6700856490068439, 0.675...\n",
       "                                 10       [0.6144334657319936, 0.7070197229417343, 0.655...\n",
       "double_mse                       1        [-0.05394638622518433, 0.03516988754184969, 0....\n",
       "                                 2        [0.1882970095744163, 0.37517943187615777, 0.38...\n",
       "                                 3        [0.34125896643085873, 0.4743856770761571, 0.46...\n",
       "                                 4        [0.46572856851854505, 0.5665745082139404, 0.56...\n",
       "                                 5        [0.5746838768223042, 0.6324254299780624, 0.555...\n",
       "                                 6        [0.6108230247246855, 0.6188270402718572, 0.636...\n",
       "                                 7        [0.6100778356609644, 0.6360677184174326, 0.606...\n",
       "                                 8        [0.622764117540707, 0.6362886195117754, 0.6649...\n",
       "                                 9        [0.5656748779535845, 0.6530187278013475, 0.637...\n",
       "                                 10       [0.6305540649886964, 0.6520621707362289, 0.648...\n",
       "Name: test_r2, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "combined_history_path = '../data/kagglenb/models/combined_history_exp_2.pickle'\n",
    "with open(combined_history_path, 'rb') as f:\n",
    "    combined_history = pickle.load(f)\n",
    "\n",
    "# Initialize an empty list to store the rows\n",
    "rows = []\n",
    "\n",
    "# Iterate through the dictionary\n",
    "for seed, experiments in combined_history.items():\n",
    "    for experiment_name, metrics in experiments.items():\n",
    "        num_epochs = len(metrics['train_loss'])\n",
    "        for epoch in range(num_epochs):\n",
    "            row = {\n",
    "                'random_seed': seed,\n",
    "                'experiment_name': experiment_name,\n",
    "                'epoch': epoch + 1,\n",
    "                'train_loss': metrics['train_loss'][epoch],\n",
    "                'test_loss': metrics['test_loss'][epoch],\n",
    "                'train_r2': metrics['train_r2'][epoch],\n",
    "                'test_r2': metrics['test_r2'][epoch],\n",
    "                'test_r2_with_catboost': metrics['test_r2_with_catboost'][epoch]\n",
    "            }\n",
    "            rows.append(row)\n",
    "\n",
    "# Convert the list of rows into a DataFrame\n",
    "history2 = pd.DataFrame(rows)\n",
    "\n",
    "# # Display the DataFrame\n",
    "# print(history2)\n",
    "\n",
    "# Group by experiment name and epoch, then calculate mean and std\n",
    "grouped_history2 = history2.groupby(['experiment_name', 'epoch']).agg(\n",
    "    train_loss_mean=('train_loss', 'mean'),\n",
    "    train_loss_std=('train_loss', 'std'),\n",
    "    test_loss_mean=('test_loss', 'mean'),\n",
    "    test_loss_std=('test_loss', 'std'),\n",
    "    train_r2_mean=('train_r2', 'mean'),\n",
    "    train_r2_std=('train_r2', 'std'),\n",
    "    test_r2_mean=('test_r2', 'mean'),\n",
    "    test_r2_std=('test_r2', 'std'),\n",
    "    test_r2_with_catboost_mean=('test_r2_with_catboost', 'mean'),\n",
    "    test_r2_with_catboost_std=('test_r2_with_catboost', 'std')\n",
    ").reset_index()\n",
    "\n",
    "# Display the grouped DataFrame\n",
    "print(\"\\nGrouped DataFrame with Mean and Std:\")\n",
    "print(grouped_history2)\n",
    "\n",
    "# for each experiment and epoch, get arrray of test r2 values\n",
    "test_r22 = history2.groupby(['experiment_name', 'epoch'])['test_r2'].apply(list)\n",
    "test_r22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "double_huber = test_r2['double_huber'][10]\n",
    "double_huber_1p_descriptions_tsdae = test_r2['double_huber_1p_descriptions_tsdae'][7]\n",
    "double_huber_1p_sentences_tsdae = test_r22['double_huber_1p_sentences_tsdae'][8]\n",
    "double_mse = test_r22['double_mse'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "double_mse vs double_huber\n",
      "double_mse mean and std: 0.643790320283712 0.009456343190047173\n",
      "double_huber mean and std: 0.657038370755114 0.006400224096878066\n",
      "p_val: 0.03094280288715685\n",
      "double_huber vs double_huber_1p_descriptions_tsdae\n",
      "double_huber mean and std: 0.657038370755114 0.006400224096878066\n",
      "double_huber_1p_descriptions_tsdae mean and std: 0.6704405642511683 0.012015253028076402\n",
      "p_val: 0.3146091768684681\n",
      "double_huber vs double_huber_1p_sentences_tsdae\n",
      "double_huber mean and std: 0.657038370755114 0.006400224096878066\n",
      "double_huber_1p_sentences_tsdae mean and std: 0.6629804066368518 0.012709693529623515\n",
      "p_val: 0.584592529403805\n"
     ]
    }
   ],
   "source": [
    "# run t test\n",
    "# consider samples dependent\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "print('double_mse vs double_huber')\n",
    "print('double_mse mean and std:', np.mean(double_mse), np.std(double_mse))\n",
    "print('double_huber mean and std:', np.mean(double_huber), np.std(double_huber))\n",
    "t_stat, p_val = stats.ttest_rel(double_mse, double_huber)\n",
    "print('p_val:', p_val)\n",
    "\n",
    "print('double_huber vs double_huber_1p_descriptions_tsdae')\n",
    "print('double_huber mean and std:', np.mean(double_huber), np.std(double_huber))\n",
    "print('double_huber_1p_descriptions_tsdae mean and std:', np.mean(double_huber_1p_descriptions_tsdae), np.std(double_huber_1p_descriptions_tsdae))\n",
    "t_stat, p_val = stats.ttest_rel(double_huber, double_huber_1p_descriptions_tsdae)\n",
    "print('p_val:', p_val)\n",
    "\n",
    "print('double_huber vs double_huber_1p_sentences_tsdae')\n",
    "print('double_huber mean and std:', np.mean(double_huber), np.std(double_huber))\n",
    "print('double_huber_1p_sentences_tsdae mean and std:', np.mean(double_huber_1p_sentences_tsdae), np.std(double_huber_1p_sentences_tsdae))\n",
    "t_stat, p_val = stats.ttest_rel(double_huber, double_huber_1p_sentences_tsdae)\n",
    "print('p_val:', p_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-12-13 10:58:21--  https://drive.usercontent.google.com/download?id=1Hysy7OYhugP0lrvn7sCfckNk0AUx2N69&export=download&authuser=1&confirm=t\n",
      "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 172.217.21.161\n",
      "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|172.217.21.161|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 35688 (35K) [application/octet-stream]\n",
      "Saving to: ‘./catboost_preds.npy’\n",
      "\n",
      "./catboost_preds.np 100%[===================>]  34,85K  --.-KB/s    in 0,006s  \n",
      "\n",
      "2024-12-13 10:58:23 (5,77 MB/s) - ‘./catboost_preds.npy’ saved [35688/35688]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4445,)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!wget --no-check-certificate 'https://drive.usercontent.google.com/download?id=1Hysy7OYhugP0lrvn7sCfckNk0AUx2N69&export=download&authuser=1&confirm=t' -O './catboost_preds.npy'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "catboost_preds = np.load('./catboost_preds.npy')\n",
    "\n",
    "catboost_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "print(arr.shape)\n",
    "lst = np.zeros()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R² scores: [-7.1896, 0.3134, 0.5265, 0.6012, 0.6429, 0.6708, 0.6926, 0.7082, 0.7247, 0.7405]\n",
      "Test R² scores: [0.0964, 0.3356, 0.5409, 0.6101, 0.5763, 0.6057, 0.5879, 0.685, 0.6878, 0.6429]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_r2_scores = [-7.1896, 0.3134, 0.5265, 0.6012, 0.6429, 0.6708, 0.6926, 0.7082, 0.7247, 0.7405]\n",
    "test_r2_scores = [0.0964, 0.3356, 0.5409, 0.6101, 0.5763, 0.6057, 0.5879, 0.6850, 0.6878, 0.6429]\n",
    "\n",
    "print(\"Train R² scores:\", train_r2_scores)\n",
    "print(\"Test R² scores:\", test_r2_scores)\n",
    "\n",
    "# plot train and test R² scores, skip first epoch\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(2, len(train_r2_scores) + 1), train_r2_scores[1:], label=\"train\")\n",
    "plt.plot(range(2, len(test_r2_scores) + 1), test_r2_scores[1:], label=\"test\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"R² score\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R² scores: [-8.1284, 0.4008, 0.5746, 0.6356, 0.6651, 0.6858, 0.7049, 0.7188, 0.7335, 0.7437]\n",
      "Test R² scores: [0.17, 0.3756, 0.491, 0.5895, 0.5978, 0.657, 0.6208, 0.6376, 0.6502, 0.6318]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_r2_scores = [-8.1284, 0.4008, 0.5746, 0.6356, 0.6651, 0.6858, 0.7049, 0.7188, 0.7335, 0.7437]\n",
    "test_r2_scores = [0.1700, 0.3756, 0.4910, 0.5895, 0.5978, 0.6570, 0.6208, 0.6376, 0.6502, 0.6318]\n",
    "\n",
    "print(\"Train R² scores:\", train_r2_scores)\n",
    "print(\"Test R² scores:\", test_r2_scores)\n",
    "\n",
    "\n",
    "# plot train and test R² scores, skip first epoch\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(2, len(train_r2_scores) + 1), train_r2_scores[1:], label=\"train\")\n",
    "plt.plot(range(2, len(test_r2_scores) + 1), test_r2_scores[1:], label=\"test\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"R² score\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. EDA - # of tokens per job and title+skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ai-forever/sbert_large_nlu_ru\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([    2, 29213, 36085, 25137, 55184,    18,  1499, 59125,    21,    12,\n",
      "         6003, 10730,    13,   745,   793,    12,  6003,  4064,    13,   548,\n",
      "         4884, 12136, 43988,     4, 16908,    18,     3,  1278,  3693,     3,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "tensor([    2, 29213, 36085, 25137, 55184,    18,  1499, 59125,    21,    12,\n",
      "         6003, 10730,    13,   745,   793,    12,  6003,  4064,    13,   548,\n",
      "         4884, 12136, 43988,     4, 16908,    18,     3,  1278,  3693,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "tensor([    2, 29213, 36085, 25137, 55184,    18, 35631,   705, 56328,    16,\n",
      "        39099,   548,  4884, 12136,  4432,     4,    18,     3,  1278,  3693,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# model = SentenceTransformer('sergeyzh/rubert-tiny-turbo')\n",
    "tokenizer = AutoTokenizer.from_pretrained('sergeyzh/rubert-tiny-turbo')\n",
    "\n",
    "sentence = \"some text\"\n",
    "prompt = \"\"\"\\\n",
    "Далее указано описание вакансии.\\\n",
    "По шкале 1 (очень мало) до 100 (очень много) на этой позиции платят [MASK] рублей.[SEP]\"\"\"\n",
    "prompt_tokens = tokenizer.tokenize(prompt)\n",
    "\n",
    "out = tokenizer(\n",
    "    prompt + sentence,\n",
    "            max_length=None,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "            )\n",
    "print(out['input_ids'][0][:50])\n",
    "\n",
    "sentence = \"some text\"\n",
    "prompt = \"\"\"\\\n",
    "[CLS] Далее указано описание вакансии.\\\n",
    "По шкале 1 (очень мало) до 100 (очень много) на этой позиции платят [MASK] рублей.[SEP]\"\"\"\n",
    "\n",
    "out = tokenizer(\n",
    "    prompt + sentence,\n",
    "            max_length=None,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "            add_special_tokens=False\n",
    "            )\n",
    "print(out['input_ids'][0][:50])\n",
    "\n",
    "sentence = \"some text\"\n",
    "prompt = \"\"\"\\\n",
    "[CLS] Далее указано описание вакансии. \\\n",
    "Судя по описанию, зарплата на этой позиции составляет [MASK].[SEP]\\\n",
    "\"\"\"\n",
    "\n",
    "out = tokenizer(\n",
    "    [prompt + sentence, 2 * prompt + sentence],\n",
    "            max_length=None,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "            add_special_tokens=False\n",
    "            )\n",
    "print(out['input_ids'][0][:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2048])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask_raw = out['attention_mask']\n",
    "attention_mask_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2048])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask_raw_bool = (attention_mask_raw == 0).bool()\n",
    "attention_mask_raw_bool.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([    2, 29213, 36085, 25137, 55184,    18, 35631,   705, 56328,    16,\n",
      "        39099,   548,  4884, 12136,  4432,     4,    18,     3,  1278, 14220,\n",
      "         6774, 14220,  6774, 14220,  6774, 14220,  6774, 14220,  6774, 14220,\n",
      "         6774, 14220,  6774, 14220,  6774, 14220,  6774, 14220,  6774, 14220,\n",
      "         6774, 14220,  6774, 14220,  6774, 14220,  6774, 14220,  6774, 14220,\n",
      "         6774, 14220,  6774, 14220,  6774, 14220,  6774, 14220,  6774, 14220,\n",
      "         6774, 14220,  6774, 14220,  6774, 14220,  6774, 14220,  6774, 14220,\n",
      "         6774, 14220,  6774, 14220,  6774, 14220,  6774, 14220,  6774, 14220,\n",
      "         6774, 14220,  6774, 14220,  6774, 14220,  6774, 14220,  6774, 14220,\n",
      "         6774, 14220,  6774, 14220,  6774, 14220,  6774, 14220,  6774, 14220])\n"
     ]
    }
   ],
   "source": [
    "sentence = 50 * \"some text\"\n",
    "prompt = \"\"\"\\\n",
    "[CLS] Далее указано описание вакансии. \\\n",
    "Судя по описанию, зарплата на этой позиции составляет [MASK].[SEP]\\\n",
    "\"\"\"\n",
    "\n",
    "out2 = tokenizer(\n",
    "    [prompt + sentence, 2 * prompt + sentence],\n",
    "            max_length=None,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "            add_special_tokens=False\n",
    "            )\n",
    "print(out2['input_ids'][0][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2048])\n",
      "torch.Size([16, 2048, 2048])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "seq_len2 = 2048\n",
    "seq_len1 = 2048\n",
    "\n",
    "attention_mask_raw2 = out2['attention_mask']\n",
    "print(attention_mask_raw2.shape)\n",
    "\n",
    "# attention_mask_raw_bool2 = (attention_mask_raw2 == 0).unsqueeze(1).expand(-1, attention_mask_raw2.size(1), -1).bool()\n",
    "attention_mask_raw_bool2 = torch.zeros((16, seq_len2, seq_len1), dtype=torch.float32)\n",
    "# attn_mask[attention_mask2 == 0, :] = float('-inf')  # Prevent query padding from attending\n",
    "print(attention_mask_raw_bool2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(15), tensor(4))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = (out['input_ids'][0] == 4)\n",
    "# get the first True index without cpu\n",
    "arr.nonzero(as_tuple=True)[0][0], out['input_ids'][0][15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    2, 32840,  9311,     3,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = out['input_ids']\n",
    "input_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "text input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_length\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(out)\n",
      "File \u001b[0;32m~/miniconda3/envs/ods-final-project-salary/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2860\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2858\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_target_context_manager:\n\u001b[1;32m   2859\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_input_mode()\n\u001b[0;32m-> 2860\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mall_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2861\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2862\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_target_mode()\n",
      "File \u001b[0;32m~/miniconda3/envs/ods-final-project-salary/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2920\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m   2917\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   2919\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_valid_text_input(text):\n\u001b[0;32m-> 2920\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2921\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2922\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor `List[List[str]]` (batch of pretokenized examples).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2923\u001b[0m     )\n\u001b[1;32m   2925\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_valid_text_input(text_pair):\n\u001b[1;32m   2926\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2927\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2928\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor `List[List[str]]` (batch of pretokenized examples).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2929\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: text input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples)."
     ]
    }
   ],
   "source": [
    "out = tokenizer(\n",
    "    input_ids[0],\n",
    "            max_length=512, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "привет мир меня зовут андреи. я люблю как твои [MASK]?\n",
      "привет мир меня зовут андреи. как твои [MASK]?\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "def tokenize_with_prompt(input_strings, prompt_strings, max_length, model_name='bert-base-uncased'):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    \n",
    "    tokenized_outputs = []\n",
    "    \n",
    "    for input_str, prompt_str in zip(input_strings, prompt_strings):\n",
    "        # Tokenize the prompt string\n",
    "        prompt_tokens = tokenizer(prompt_str, add_special_tokens=False)['input_ids']\n",
    "        \n",
    "        # Calculate the remaining length for the input string\n",
    "        remaining_length = max_length - len(prompt_tokens) - 1  # -1 for the [SEP] token\n",
    "        \n",
    "        # Tokenize the input string and truncate if necessary\n",
    "        input_tokens = tokenizer(input_str, add_special_tokens=False, truncation=True, max_length=remaining_length)['input_ids']\n",
    "        \n",
    "        # Concatenate the input tokens and prompt tokens\n",
    "        # combined_tokens = input_tokens + [tokenizer.sep_token_id] + prompt_tokens\n",
    "        combined_tokens = input_tokens + prompt_tokens\n",
    "        \n",
    "        # Convert tokens back to string\n",
    "        tokenized_output = tokenizer.decode(combined_tokens, skip_special_tokens=False)\n",
    "        tokenized_outputs.append(tokenized_output)\n",
    "    \n",
    "    return tokenized_outputs\n",
    "\n",
    "# Example usage\n",
    "sentence1 = \"привет мир меня зовут Андрей. я люблю путешествовать.\"\n",
    "sentence2 = \"привет мир меня зовут Андрей. \"\n",
    "input_strings = [sentence1, sentence2]\n",
    "prompt_strings = [\"как твои [MASK]?\"]*2\n",
    "max_length = 40\n",
    "model_name = 'sergeyzh/rubert-tiny'\n",
    "\n",
    "prompt = \"как твои [MASK]?\"\n",
    "\n",
    "result = tokenize_with_prompt(input_strings, prompt_strings, max_length)\n",
    "for res in result:\n",
    "    print(res)\n",
    "\n",
    "prompt = \"\"\"\\\n",
    "Далее указано описание вакансии. По шкале 1 (очень мало) до 100 (очень много) на этой позиции платят [MASK] рублей.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    2, 65769, 71961, 82135,     3,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['input_ids'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[101, 4366, 118, 1721, 84349, 161, 102],\n",
       " [101, 693, 725, 37038, 376, 161, 102]]"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1 = \"Какая у вас специализация?\"\n",
    "q2 = \"Что вы изучаете?\"\n",
    "\n",
    "seq1 = tokenizer.encode(text=q1, return_tensors='pt')\n",
    "\n",
    "out = tokenizer.batch_encode_plus(\n",
    "            [q1,q2],\n",
    "            add_special_tokens=True,\n",
    "            max_length=None,\n",
    "            padding='max_length',\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "out['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'какая', 'у', 'вас', 'специализация', '?', '[SEP]']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 512])"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1 = \"Какая у вас специализация?\"\n",
    "q2 = \"Что вы изучаете?\"\n",
    "\n",
    "seq1 = tokenizer.encode(text=q1, return_tensors='pt')\n",
    "print(tokenizer.convert_ids_to_tokens(seq1[0]))\n",
    "out = tokenizer(\n",
    "            [q1,q2]*2,\n",
    "            max_length=512, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "out['attention_mask'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(self.tokenized_texts1['input_ids']): 2\n",
      "len(self.tokenized_texts2['input_ids']): 2\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Suppress all FutureWarnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "def set_seed(seed: int) -> None:\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Set the seed\n",
    "SEED = 42\n",
    "set_seed(SEED)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_name = \"cointegrated/LaBSE-en-ru\"\n",
    "\n",
    "\n",
    "# Dataset for dual textual features\n",
    "class DualTextDataset(Dataset):\n",
    "    def __init__(self, text_col_1, text_col_2, targets, tokenizer, max_len):\n",
    "        # Pre-tokenize and store inputs\n",
    "        self.tokenized_texts1 = tokenizer(text_col_1, max_length=max_len, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "        self.tokenized_texts2 = tokenizer(text_col_2, max_length=max_len, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "        self.targets = targets\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        print(f\"len(self.tokenized_texts1['input_ids']): {len(self.tokenized_texts1['input_ids'])}\")\n",
    "        print(f\"len(self.tokenized_texts2['input_ids']): {len(self.tokenized_texts2['input_ids'])}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Return only the slice for idx\n",
    "        inputs1 = {key: val[idx] for key, val in self.tokenized_texts1.items()}\n",
    "        inputs2 = {key: val[idx] for key, val in self.tokenized_texts2.items()}\n",
    "        target = torch.tensor(self.targets[idx], dtype=torch.float)\n",
    "        return inputs1, inputs2, target\n",
    "    \n",
    "q1 = \"Какая у вас специализация?\"\n",
    "q2 = \"Что вы изучаете?\"\n",
    "q3 = \"Какие у вас интересы?\"\n",
    "q4 = \"Что вас интересует?\"\n",
    "\n",
    "text_col_1 = [q1, q2, ]\n",
    "text_col_2 = [q3, q4, ]\n",
    "targets = [1, 0]\n",
    "max_len = 128\n",
    "\n",
    "dataset = DualTextDataset(text_col_1, text_col_2, targets, tokenizer, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22224 entries, 0 to 22223\n",
      "Data columns (total 13 columns):\n",
      " #   Column                              Non-Null Count  Dtype  \n",
      "---  ------                              --------------  -----  \n",
      " 0   title                               22224 non-null  object \n",
      " 1   location                            22224 non-null  object \n",
      " 2   company                             22224 non-null  object \n",
      " 3   skills                              14384 non-null  object \n",
      " 4   description                         22224 non-null  object \n",
      " 5   salary_from                         22224 non-null  float64\n",
      " 6   source                              22224 non-null  object \n",
      " 7   experience_from                     22224 non-null  float64\n",
      " 8   log_salary_from                     22224 non-null  float64\n",
      " 9   description_no_numbers              22224 non-null  object \n",
      " 10  description_no_numbers_with_skills  22224 non-null  object \n",
      " 11  experience_to_adjusted_10           22224 non-null  float64\n",
      " 12  description_size                    22224 non-null  int64  \n",
      "dtypes: float64(4), int64(1), object(8)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# read the file\n",
    "df = pd.read_csv('../data/getmatch_hh_combined_for_catboost_relevant_columns_only.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Далее указано описание вакансии.По шкале 1 (очень мало) до 100 (очень много) на этой позиции платят [MASK] рублей.[SEP]\\nПутешествия — онлайн-тревел-агентство в экосистеме компании. Мы построили сервис по продаже авиабилетов с нуля и постоянно развиваем его. Наши клиенты могут бронировать авиабилеты, отели, подбирать онлайн-туры и покупать страховку. Все это можно сделать на удобной площадке: в приложении или на сайте.\\nАналитик в Путешествиях — не калькулятор в руках продакт-менеджера, а полноценный компаньон и участник разработки продукта.\\nВот как мы работаем\\nУчаствуем во всех процессах discovery, ищем точки роста и влияем на продукт. Мы помогаем определять вектор развития команды, ее метрики и долгосрочные цели, а еще предлагаем идеи улучшения продукта, основываясь на данных.\\nДизайним и анализируем эксперименты. У нас развитая культура тестирования и своя A/B-платформа: все фичи проходят через эксперименты, ничего не выкатывается «на глаз».\\nСоздаем дашборды и аналитические инструменты. Есть четкий процесс создания дашборда, навигатор отчетов, библиотека метрик.\\nУчаствуем в общеаналитических проектах. Например, развиваем discovery в компании вместе с коллегами-аналитиками или создаем единую систему инструментария и развиваем Data Driven-культуру в рамках проекта Data Informed.\\nМы тесно интегрированы со всеми нефинансовыми сервисами, проводим обучающие встречи, устраиваем аналитические тусовки — официальные и неформальные, выступаем на митапах.\\nВ команду ждем\\nаналитика\\n, который хочет расти, реализовываться и влиять на бизнес вместе с компанией талантливых коллег.\\nЧто предстоит делать\\nВыстраивать систему метрик в продукте.\\nАнализировать продуктовые фичи и гипотезы.\\nПроводить А/В-тесты.\\nИсследовать поведение пользователей, находить проблемы и точки роста.\\nВыступать партнером продуктовых команд при принятии решений на основе данных.\\nПринимать участие в формировании и приоритизации продуктовых планов на основе проведенных исследований.\\nСоздавать дашборды и инструменты аналитики — мы используем Tableau и Superset.\\nМы ждем, что вы\\nИмеете опыт работы в роли продуктового аналитика от года.\\nИмеете опыт дизайна и подведения итогов А/В-тестов.\\nИмеете опыт построения дашбордов в любой BI-системе.\\nЗнаете основы математической статистики и теории вероятностей.\\nЗнаете принципы работы реляционных баз данных и владеете SQL на хорошем уровне.\\nУмеете видеть за числами действия реальных пользователей и объяснять, почему изменилось их поведение.\\nПроактивно подходите к решению задач: способны самостоятельно разобраться в ситуации, задать правильные вопросы, собрать информацию и сделать выводы, которые приведут к принятию наилучшего решения.\\nМы предлагаем\\nРаботу в офисе или удаленно — по договоренности.\\nПлатформу обучения и развития «Апгрейд». Курсы, тренинги, вебинары и базы знаний. Поддержку менторов и наставников, помощь в поиске точек роста и карьерном развитии.\\nКомплексную программу заботы о здоровье. Оформим полис ДМС с широким покрытием и страховку от несчастных случаев. Предложим льготные условия страхования для ваших близких.\\nВозможность работы в аккредитованной ИТ-компании.\\nЛинейку льготных тарифов на продукты Т-Банка.\\nЧастичную компенсацию затрат на спорт.\\nWell-being программу, которая помогает улучшить психологическое и физическое здоровье, а также разобраться с юридическими и финансовыми вопросами.\\nТри дополнительных дня отпуска в год.\\nДостойную зарплату — обсудим ее на собеседовании.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"\\\n",
    "Далее указано описание вакансии.\\\n",
    "По шкале 1 (очень мало) до 100 (очень много) на этой позиции платят [MASK] рублей.[SEP]\n",
    "\"\"\"\n",
    "\n",
    "df['description_with_prompt'] = prompt + df['description']\n",
    "df['description_with_prompt'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize the description column\n",
    "# and build histogram of # tokens per job\n",
    "n_tokens = df['description_no_numbers'].apply(lambda x: len(tokenizer.encode(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    22224.000000\n",
      "mean       331.156093\n",
      "std        163.239483\n",
      "min         27.000000\n",
      "1%          62.000000\n",
      "5%         110.000000\n",
      "50%        308.000000\n",
      "90%        536.000000\n",
      "95%        631.000000\n",
      "99%        834.770000\n",
      "max       1535.000000\n",
      "Name: description_no_numbers, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Number of tokens in job description_no_numbers. rubert tiny turbo tokenizer'}>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "# print quantile and histogram\n",
    "print(n_tokens.describe(percentiles=[0.5, 0.9, 0.05, 0.01, 0.95, 0.99]))\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title('Number of tokens in job description_no_numbers. rubert tiny turbo tokenizer')\n",
    "n_tokens.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first 512:\n",
      "Stellar 2H Group - c 2005 года мы разрабатываем собственные и заказные сложные и высоконагруженные IT-сервисы, а также оказываем услуги партнерским IT-компаниям. По данной позиции мы выступаем в качестве HR-партнера для крупного системного интегратора, который более 12 лет занимается информационной и сетевой безопасностью. В команде работают одни из лучших технических специалистов. Благодаря сплоченному коллективу - нет бюрократии и присущей большим компаниям текучки. У вас будет возможность пройти весь путь рядом с опытной командой разработчиков, получив хорошие бонусы, а также при желании вырасти до руководства разработкой. Ниже мы подробно описали суть задач и вакансии, чтобы у вас осталось как можно меньше вопросов. Инженеры в нашей Компании сфокусированы и плотно работают со всеми линейками продуктов Check Point — шлюзы (включая масштабируемые платформы), защита рабочих станций, мобильная безопасность, защита от продвинутых и направленных угроз, безопасность в облачных инфраструктурах. В нашу проектную и команду технической поддержки мы ищем инженеров с достаточным прикладным опытом (уровней junior-middle-senior ) по решениям Check Point в этих направлениях. Если у Вас есть хороший инженерный опыт работы с продуктами компании Check Point , Вам нравиться данный вендор, вы хотите постоянно развиваться в экосистеме вендора и Информационной Безопасности в целом, — эта вакансия для Вас. Важно понимать: - До 90% времени на этой вакансии посвящено плотной работе именно с Check Point , его продуктами, реализуемыми ими функционалами и сервисами, взаимодействующими с ним. Кандидат должен хотеть именно глубокого погружения в Check Point и быть заинтересован в этом. Оставшиеся 10% времени - это работа с сетевой инфраструктурой, в которую встраиваются решения Check Point; интеграция с инфраструктурными сервисами и понимание основных принципов работы защищаемых решением приложений, сервисов и процессов. - Это работа в системном интеграторе , связанная с постоянно возникающими новыми проектами разных объёмов, уровней сложности, направленности и организованности; необходимостью постоянного обучения, развития и поднятия собственной экспертизы; личной активной работой с постоянно меняющимися проектными командами на стороне Заказчика. Если Вы сталкивались и минимально работали с продуктами Check Point , но у Вас нет достаточных знаний и умений в работе с ними, зато есть хороший опыт в сетевых технологиях и/или инфраструктурных сервисах, а также, главное - желание сфокусироваться и развивать свою экспертизу по продуктам Check Point, а также реализуемого ими функционала в области Информационной Безопасности, мы готовы провести обучение на базе нашей Компании в формате самообучения и выполнения тестового задания. Обучение включает доступ к стендам, в базу знаний Check Point с партнёрским уровнем, ко всей документации, CookBook'ам и HowTo, демонстрационным и учебным материалам вендора, экспертным знаниям наставника-архитектора и тестовое задание, имитирующее реальную инфраструктуру стандартного Заказчика, выполненную и защищённую на продуктах Check Point. На этапе обучения выплачивается заработная плата. - Многие считают специальность инженера тех. поддержки непрестижной. В специалистах техподдержки они видят операторов, которые работают по скрипту, ищут ответ в базе знаний и копируют его. У нас это совершенно не так! Наша техподдержка славится на рынке крайне высокой экспертностью с глубоким погружением в тяжёлые нестандартные кейсы любого уровня. В нашей техподдержке работают высококлассные инженеры с крайне высокими компетенциями. В своей работе они поддерживают весь спектр продуктов вендора и реализуемого ими функционала, обрабатывают для этого большие объёмы данных из большого количества источников, отвечают на любые типы вопросов и одинаково\n",
      " ... \n"
     ]
    }
   ],
   "source": [
    "# look at the longest job\n",
    "print('first 512:')\n",
    "print(' '.join(df.loc[n_tokens.idxmax(), 'description_no_numbers'].split()[:512]))\n",
    "print(' ... ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last -512:\n",
      "как проблем с работоспособностью, так и выполнения настроек; Взаимодействие с технической поддержкой Check Point. Непрерывное сквозное изучение нового функционала и новых решений Check Point; Привлечение с ростом экспертизы к реализации комплексных проектов по информационной безопасности на базе продуктов Check Point в качестве аудитора, инженера внедрения, инженера сопровождения; Что мы ожидаем от вас: Опыт администрирования шлюзов безопасности Check Point версии не ниже R80; Понимание и умение настраивать основные «блэйды» (функционалы безопасности) шлюзов безопасности Check Point; Навыки поиска и устранения неисправностей, возникающих в ОС Gaia и прикладных сервисах при работе шлюзов безопасности и серверов управления Check Point; Уверенные знания протоколов сетевого взаимодействия и маршрутизации (эквивалентные сертификату CCNA), принципов построения систем информационной безопасности на базе оборудования Check Point, понимание основ криптографической защиты информации; Уверенные навыки работы в семействе ОС *nix; Понимание работы инфраструктурных сервисов Windows; Базовые навыки работы в средах виртуализации; Опыт работы с порталом поддержки Сheck Point; Приветствуется наличие честного сертификата CCSA или эквивалентных знаний; Знание английского языка на уровне чтения профильных текстов и общения с технической поддержкой вендора; Приветствуются аккуратность, быстрая обучаемость, внимательность, коммуникабельность, пунктуальность; Постоянная тяга к получению новых знаний, навыков и саморазвитию, желание развиваться и не стоять на месте — обязательно! Что мы предлагаем: Работа в Компании, аккредитованной в Минцифры в области IT; Официальное трудоустройство, оформление по ТК, соблюдение трудового законодательства; Уровень заработной платы на постоянной основе определяется исходя из Вашего опыта, с ростом экспертизы увеличивается заработная плата; Премии по результатам закрытия комплексных проектов, проектов со сложной экспертизой, быстрого закрытия проектов; Прозрачная схема карьерного, профессионального и зарплатного роста; Понятная система мотивации; Обсуждаемые возможности открытия индивидуальных кредитных линий на базе Компании; Продуманное и удобное ДМС от Ингосстрах; Скидки и специальные предложения в рамках участия в программе страхования \"Большая семья\" от СК Согласие; Корпоративная мобильная связь; Постоянный цикл обучения для сотрудников — как на базе Компании, так и с привлечением вендорских и внешних программ обучения и увеличения экспертизы; Демо-лицензии, виртуализированные стенды, обучение и сертификация за счёт работодателя; Полный технический экспертный доступ в базы знаний, ко всей документации, CookBook'ам и HowTo, демонстрационным и учебным материалам всем релевантных вендоров; Регулярные внутренние митапы, демо-дни, открытые микрофоны, обмен опытом; Для работы предоставляются мощные ноутбуки и доступ на высокопроизводительную ферму виртуализации на блейд-шасси; Просторное рабочее место в удобном красивом и комфортном офисе с зоной отдыха в 1 минуте от метро Нагорная, в офисе вкусный чай, кофе, шоколад, печенье, свежие фрукты; Возможность согласования свободного графика, удалённой / гибридной работы, гибкого начала / окончания рабочего дня; Общие периодические совместные корпоративные мероприятия; Прозрачность технических, проектных и бизнес-процессов, низкая забюрократизированность Компании; Интересная, интенсивная работа в здоровой атмосфере дружного коллектива единомышленников и профессионалов, в которой налажен процесс обмена экспертизой; Горизонтальная структура, обеспечивающая свободную коммуникацию между сотрудниками; Культура в Компании, основанная на доверии и прозрачности, открытости и честности; Работа в стабильно 14 лет растущей компании, с полноценной аккредитацией в Минкомсвязи РФ и полным портфелем лицензирующих документов от ФСБ и ФСТЭК; Приветствуются и поощряются инициативы; творческий подход; желание участвовать не только в реализации, но и в разработке и обсуждении проектов; желание развиваться и развивать других; Сотрудники могут стать спикерами на внутренних и внешних митапах, авторами блогов или бизнес-идей и даже получить финансирование на их реализацию.\n"
     ]
    }
   ],
   "source": [
    "# look at the longest job\n",
    "print('last -512:')\n",
    "print(' '.join(df.loc[n_tokens.idxmax(), 'description_no_numbers'].split()[-512:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обязанности:     Административно-хозяйственная работа, проведение мероприятий, выставок, написание сценариев.     Требования:     Дисциплинированность, ответственность.  \n"
     ]
    }
   ],
   "source": [
    "# look at the shortest job\n",
    "print(df.loc[n_tokens.idxmin(), 'description_no_numbers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    22224.000000\n",
      "mean        48.236411\n",
      "std         21.915149\n",
      "min         20.000000\n",
      "1%          23.000000\n",
      "5%          25.000000\n",
      "50%         43.000000\n",
      "90%         77.000000\n",
      "95%         90.000000\n",
      "99%        122.000000\n",
      "max        215.000000\n",
      "Name: title_company_location_skills_source, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Number of tokens in title_company_location_skills_source'}>"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "title_company_location_skills_feature_template = \"\"\"\n",
    "Позиция: {position}\n",
    "Компания: {company}\n",
    "Место: {location}\n",
    "Навыки: {skills}\n",
    "Источник: {source}\n",
    "\"\"\"\n",
    "\n",
    "df['title_company_location_skills_source'] = df.apply(lambda x: title_company_location_skills_feature_template.format(\n",
    "    position=x['title'],\n",
    "    company=x['company'],\n",
    "    location=x['location'],\n",
    "    skills=x['skills'],\n",
    "    source=x['source']\n",
    "), axis=1)\n",
    "\n",
    "# tokenize the title_company_location_skills column, print description and plot histogram\n",
    "\n",
    "n_tokens = df['title_company_location_skills_source'].apply(lambda x: len(tokenizer.encode(x)))\n",
    "\n",
    "print(n_tokens.describe(percentiles=[0.5, 0.9, 0.05, 0.01, 0.95, 0.99]))\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title('Number of tokens in title_company_location_skills_source')\n",
    "n_tokens.hist(bins=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Позиция: Специалист по программному обеспечению Компания: Министерство Цифрового Развития и Связи Кузбасса Место: Кемерово Навыки: знание языка программирования - JavaScript;, - основы управления проектами и описания бизнес-процессов;, - особенности создания, внедрения и развития программно-технической, информационно-коммуникационной, - особенности подготовки и согласования технической документации, с учетом стандартов и нормативных, - знания и умения в области аппаратного и программного обеспечения, возможностей и особенностей прим, - общие вопросы в области обеспечения информационной безопасности,, - общие вопросы в области работы с внутренними и периферийными устройствами компьютера,, - общие вопросы в области работы с информационно–телекоммуникационными сетями, в том числе сетью Инт, - облачные решения и особенности их использования;, - особенности создания, внедрения и развития цифровых продуктов., Уверенный пользователь ПК;, Умение работать с большим объемом информации, обучаемость;, Грамотная письменная и устная речь;, Вежливость, неконфликтность, стрессоустойчивость; Источник: hh\n"
     ]
    }
   ],
   "source": [
    "# look at the longest title_company_location_skills\n",
    "print(' '.join(df.loc[n_tokens.idxmax(), 'title_company_location_skills_source'].split()[:512]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Позиция: Инженер Компания: Александрия Место: Белгород Навыки: nan Источник: hh\n"
     ]
    }
   ],
   "source": [
    "# look at the shortest gest title_company_location_skills\n",
    "print(' '.join(df.loc[n_tokens.idxmin(), 'title_company_location_skills_source'].split()[:512]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22224 entries, 0 to 22223\n",
      "Data columns (total 14 columns):\n",
      " #   Column                                Non-Null Count  Dtype  \n",
      "---  ------                                --------------  -----  \n",
      " 0   title                                 22224 non-null  object \n",
      " 1   location                              22224 non-null  object \n",
      " 2   company                               22224 non-null  object \n",
      " 3   skills                                14384 non-null  object \n",
      " 4   description                           22224 non-null  object \n",
      " 5   salary_from                           22224 non-null  float64\n",
      " 6   source                                22224 non-null  object \n",
      " 7   experience_from                       22224 non-null  float64\n",
      " 8   log_salary_from                       22224 non-null  float64\n",
      " 9   description_no_numbers                22224 non-null  object \n",
      " 10  description_no_numbers_with_skills    22224 non-null  object \n",
      " 11  experience_to_adjusted_10             22224 non-null  float64\n",
      " 12  description_size                      22224 non-null  int64  \n",
      " 13  title_company_location_skills_source  22224 non-null  object \n",
      "dtypes: float64(4), int64(1), object(9)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22224 entries, 0 to 22223\n",
      "Data columns (total 14 columns):\n",
      " #   Column                                Non-Null Count  Dtype  \n",
      "---  ------                                --------------  -----  \n",
      " 0   title                                 22224 non-null  object \n",
      " 1   company                               22224 non-null  object \n",
      " 2   location                              22224 non-null  object \n",
      " 3   skills                                22224 non-null  object \n",
      " 4   source                                22224 non-null  object \n",
      " 5   description_no_numbers_with_skills    22224 non-null  object \n",
      " 6   experience_from                       22224 non-null  float64\n",
      " 7   experience_to_adjusted_10             22224 non-null  float64\n",
      " 8   description_size                      22224 non-null  int64  \n",
      " 9   description                           22224 non-null  object \n",
      " 10  description_no_numbers                22224 non-null  object \n",
      " 11  title_company_location_skills_source  22224 non-null  object \n",
      " 12  salary_from                           22224 non-null  float64\n",
      " 13  log_salary_from                       22224 non-null  float64\n",
      "dtypes: float64(4), int64(1), object(9)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# resort the columns\n",
    "df = df[['title', 'company', 'location', 'skills', 'source', # for catboost\n",
    "         'description_no_numbers_with_skills', 'experience_from', # for catboost\n",
    "         'experience_to_adjusted_10', 'description_size', # for catboost\n",
    "         'description', 'description_no_numbers', 'title_company_location_skills_source', # for transformers\n",
    "         'salary_from', 'log_salary_from' # targets\n",
    "         ]]\n",
    "\n",
    "# fill empty skills with empty string\n",
    "df['skills'] = df['skills'].fillna('')\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the file\n",
    "df.to_csv('../data/getmatch_hh_combined_for_catboost_relevant_columns_only_and_transformers.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove (some) numbers from the description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a regex to extract all numbers from the description with 10 symbols before and after\n",
    "# save the extracted numbers in txt file, one string per line\n",
    "\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# extract all numbers from the description with 10 symbols before and after\n",
    "# this may be any symbol, not only space\n",
    "def extract_numbers(text):\n",
    "    # numbers = re.findall(r'(?<=.{0,10})\\d+(?=.*)', text) # error: look-behind requires fixed-width pattern\n",
    "    # numbers = re.findall(r'(?<=\\D{0,10})\\d+(?=\\D{0,10})', text) # error: look-behind requires fixed-width pattern\n",
    "    # numbers = re.findall(r'((оклад|плата)\\W{,3}\\d{1,}\\D?\\d{0,}\\D?\\d{0,}\\D)', text)\n",
    "    # numbers = re.findall(r'((оклад|плата)\\W{,3}\\d[\\d|\\W]+\\d)\\D', text)\n",
    "    # numbers = re.findall(r'((оклад|плата|от)\\W{,3}\\d[\\d|\\W]+\\d)(?![\\s%])', text, re.IGNORECASE)\n",
    "    pattern = r'((оклад|плата|от)\\W{,3}\\d[\\d|\\W]+\\d)\\D(?![\\s%])'\n",
    "    # плата 100.000-110.000 + 6\n",
    "    numbers = re.findall(pattern, text, re.IGNORECASE)\n",
    "    # flatten the list\n",
    "    numbers = [number for number, _ in numbers]\n",
    "\n",
    "    # return ' '.join(numbers)\n",
    "    if len(numbers) == 0:\n",
    "        return set(' ')\n",
    "    return set(numbers)\n",
    "\n",
    "# save the extracted numbers in txt file, one string per line\n",
    "# numbers = df['description'].apply(extract_numbers)\n",
    "numbers = set()\n",
    "for text in df['description_no_numbers']:\n",
    "    numbers.update(extract_numbers(text))\n",
    "# numbers = numbers[numbers.apply(len) > 0]\n",
    "# flatten the list\n",
    "# numbers = np.concatenate(numbers)\n",
    "# remove duplicates\n",
    "# numbers = list(set(numbers))\n",
    "with open('../data/extracted_numbers.txt', 'w') as f:\n",
    "    f.write('\\n'.join(numbers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aккpeдитoванная ИТ-кoмпания, рaбoтаeм c 2006 годa. Пpиглaшaeм выeздного систeмного aдминистрaтopa (начинaющeгo)   Разъeзднaя  рабoта на  личном автомобилe , бензин оплачивaeм пo тoпливной каpте. Обслуживаем компьютеры, принтеры, видеонаблюдение и другое ит-оборудование магазинов Пятерочка, Чижик, Перекресток. Выезд из дома сразу на заявку. В мобильном приложении есть перечень заявок со сроками и приоритетами. Район обслуживания: Мацеста, Хоста, Адлер   Оклад  70 000₽  на руки, оформление по договору ГПХ, с  премией 90-110 тыс   График работы гибкий. 1 плавающий выходной   Разъeзднaя рабoта на личном автомобилe, бензин оплачивaeм пo тoпливной каpте   Bыдaем: ноутбук, инстpумeнт.   Бeз опытa  paбoты с торговым и кассовым оборудованием, есть обучение, полная зарплата с первого дня   Обязателен опыт работы (даже на уверенном бытовом уровне )либо в :   настройке ПК,ПО   ПК железе   работе с проводами (например протянуть домой самому интернет)   установить, наладить подключить доп.оборудование (принтер, МФУ и пр)   Оплачивaем мoбильную связь.   Задачи :     Развозка расходных материалов, картриджей для принтеров по магазинам   Базовая настройка компьютеров по инструкции     Требования : желание учиться и работать в ИТ   Рассматриваем кандидатов, как без  опыта работы , так и с опытом по специальностям: системный администратор, сисадмин, специалист технической поддержки, монтажник слаботочных систем, техник подключения к интернет, техник по обслуживанию компьютеров, ИТ-инженер, сетевой инженер, мобильный сервисный инженер, инженер по инфраструктурным проектам   Подработку, совмещение, временное трудоустройство  не рассматриваем    \n"
     ]
    }
   ],
   "source": [
    "print(df[df['description_no_numbers'].str.contains(\"оклад  70 000\", case=False,regex=False)].description_no_numbers.iloc[0]\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Зарплата от [NUMBER] рублей. Оклад [NUMBER]  Оклад до [NUMBER] рублей, Опыт работы от 1-5 года. Зарплата [NUMBER] рублей. Опыт работы от 2-3 лет.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def replace_salary_pattern(text):\n",
    "    # pattern = r'((оклад|плата|от)\\W{,3}\\d[\\d|\\W]+\\d)(?=\\D|$)(?![\\s%])'\n",
    "    # pattern = r'((оклад|плата|от)\\W{,3}\\d[\\d|\\W]+\\d)\\D(?![\\s%лгшчк])'\n",
    "    # pattern = r'((оклад|плата|от)\\W{,3}\\d[\\d|\\W]+\\d)(?![\\d%лгшчк])'\n",
    "    pattern = r'((оклад|плата|от|до)\\W{,3}\\d[\\d|\\W]+\\d)\\D(?![%лгшчк])'\n",
    "\n",
    "    \n",
    "    def replacement(match):\n",
    "        prefix = match.group(2)\n",
    "        return f\"{prefix} [NUMBER] \"\n",
    "    \n",
    "    return re.sub(pattern, replacement, text,\n",
    "                  flags=re.IGNORECASE\n",
    "                  )\n",
    "\n",
    "# Example usage\n",
    "text = \"Зарплата от 35 000 - 60 000 рублей. Оклад 50 000. Оклад до 10000 рублей, Опыт работы от 1-5 года. Зарплата 70 000 рублей. Опыт работы от 2-3 лет.\"\n",
    "result = replace_salary_pattern(text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aккpeдитoванная ИТ-кoмпания, рaбoтаeм c 2006 годa.\n",
      "Пpиглaшaeм выeздного систeмного aдминистрaтopa (начинaющeгo)\n",
      "Разъeзднaя  рабoта на  личном автомобилe , бензин оплачивaeм пo тoпливной каpте.\n",
      "Обслуживаем компьютеры, принтеры, видеонаблюдение и другое ит-оборудование магазинов \n",
      "Пятерочка, Чижик, Перекресток. Выезд из дома сразу на заявку. \n",
      "В мобильном приложении есть перечень заявок со сроками и приоритетами. \n",
      "Район обслуживания: Мацеста, Хоста, Адлер   Оклад [NUMBER] рублей  на руки, \n",
      "оформление по договору ГПХ, с  премией 90-110 тыс  \n",
      " График работы гибкий. 1 плавающий выходной  \n",
      "   Разъeзднaя рабoта на личном автомобилe,\n",
      "     бензин оплачивaeм пo тoпливной каpте   Bыдaем: ноутбук, инстpумeнт.  \n",
      "       Бeз опытa  paбoты с торговым и кассовым оборудованием, есть обучение, \n",
      "       полная зарплата с первого дня   \n",
      "       Обязателен опыт работы (даже на уверенном бытовом уровне )либо в :  \n",
      "         настройке ПК,ПО   ПК железе   работе с проводами\n",
      "           (например протянуть домой самому интернет)  \n",
      " установить, наладить подключить доп.оборудование (принтер, МФУ и пр)   \n",
      " Оплачивaем мoбильную связь.   Задачи :     Развозка расходных материалов,\n",
      "   картриджей для принтеров по магазинам   Базовая настройка компьютеров \n",
      "   по инструкции     Требования : желание учиться и работать в ИТ  \n",
      "     Рассматриваем кандидатов, как без  опыта работы \n",
      "     , так и с опытом по специальностям: системный администратор, сисадмин, специалист технической поддержки, монтажник слаботочных систем, техник подключения к интернет, техник по обслуживанию компьютеров, ИТ-инженер, сетевой инженер, мобильный сервисный инженер, инженер по инфраструктурным проектам   Подработку, совмещение, временное трудоустройство  не рассматриваем\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"Aккpeдитoванная ИТ-кoмпания, рaбoтаeм c 2006 годa.\n",
    "Пpиглaшaeм выeздного систeмного aдминистрaтopa (начинaющeгo)\n",
    "Разъeзднaя  рабoта на  личном автомобилe , бензин оплачивaeм пo тoпливной каpте.\n",
    "Обслуживаем компьютеры, принтеры, видеонаблюдение и другое ит-оборудование магазинов \n",
    "Пятерочка, Чижик, Перекресток. Выезд из дома сразу на заявку. \n",
    "В мобильном приложении есть перечень заявок со сроками и приоритетами. \n",
    "Район обслуживания: Мацеста, Хоста, Адлер   Оклад  70 000₽  на руки, \n",
    "оформление по договору ГПХ, с  премией 90-110 тыс  \n",
    " График работы гибкий. 1 плавающий выходной  \n",
    "   Разъeзднaя рабoта на личном автомобилe,\n",
    "     бензин оплачивaeм пo тoпливной каpте   Bыдaем: ноутбук, инстpумeнт.  \n",
    "       Бeз опытa  paбoты с торговым и кассовым оборудованием, есть обучение, \n",
    "       полная зарплата с первого дня   \n",
    "       Обязателен опыт работы (даже на уверенном бытовом уровне )либо в :  \n",
    "         настройке ПК,ПО   ПК железе   работе с проводами\n",
    "           (например протянуть домой самому интернет)  \n",
    " установить, наладить подключить доп.оборудование (принтер, МФУ и пр)   \n",
    " Оплачивaем мoбильную связь.   Задачи :     Развозка расходных материалов,\n",
    "   картриджей для принтеров по магазинам   Базовая настройка компьютеров \n",
    "   по инструкции     Требования : желание учиться и работать в ИТ  \n",
    "     Рассматриваем кандидатов, как без  опыта работы \n",
    "     , так и с опытом по специальностям: системный администратор, сисадмин, специалист технической поддержки, монтажник слаботочных систем, техник подключения к интернет, техник по обслуживанию компьютеров, ИТ-инженер, сетевой инженер, мобильный сервисный инженер, инженер по инфраструктурным проектам   Подработку, совмещение, временное трудоустройство  не рассматриваем\n",
    "\"\"\".replace('₽', ' рублей')\n",
    "result = replace_salary_pattern(text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['description_no_numbers_v2'] = df['description_no_numbers']\\\n",
    "            .apply(lambda x: x.replace('₽', ' рублей'))\\\n",
    "            .apply(replace_salary_pattern)  \n",
    "# df['description_no_numbers_v2'] = df['description']\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Работа в Sminex основана на общих ценностях, культуре и целях. Мы вместе работаем, зарабатываем, развиваемся и отдыхаем. Создаём сильную команду, нанимаем лучших.\n",
      "Мы стремимся стать для сотрудников компанией мечты, работать в которой престижно и комфортно, чтобы работа в Sminex была хорошо оплачиваемым хобби.\n",
      "Что нужно делать\n",
      "Обеспечивать бесперебойную работу IT-инфраструктуры и её развитие в соответствии с потребностями компании.\n",
      "Осуществлять техническую поддержку ИТ-инфраструктуры Компании.\n",
      "Выезжать на объекты компании для решения технических задач.\n",
      "Консультировать пользователей по работе с техникой и ПО.\n",
      "Фиксировать и решать проблемы с ОС, прикладным ПО, СКС.\n",
      "Поддерживать системы автоматического распространения ПО.\n",
      "Поддерживать коммутационное оборудование и организацию СКС.\n",
      "Своевременно решать заявки, регистрировать новые заявки в Jira Service Desk.\n",
      "Мы ожидаем\n",
      "Опыт работы на аналогичной должности от 2 лет.\n",
      "Глубокое знание линейки ОС Windows.\n",
      "Понимание назначения и функционирования параметров реестра, профиля пользователя.\n",
      "Глубокие знания скриптовых языков программирования в среде Windows.\n",
      "Знание протоколов стека TCP/IP.\n",
      "Умение диагностировать и устранять проблемы с сетью.\n",
      "Умение диагностировать и решать проблемы с ОС и прикладным ПО.\n",
      "Опыт настройки и работы с активным сетевым оборудованием.\n",
      "Опыт автоматизации настройки рабочего пространства пользователей Windows.\n",
      "Опыт автоматизации распространения ПО и ОС.\n",
      "Умение общаться с пользователями.\n",
      "Опыт работы в системах Service Desk.\n",
      "Мы предлагаем\n",
      "Прозрачное и достойное вознаграждение (fix+бонус).\n",
      "График работы 5/2 с 10:00 до [NUMBER] \n",
      "Офис в пешей доступности от метро Новослободская/Маяковская.\n",
      "Профессиональный коллектив.\n",
      "Социальный пакет: бесплатные обеды, ежедневные полдники, мобильная связь, ДМС (после испытательного срока).\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    df[df['description_no_numbers'] != df['description_no_numbers_v2']]\n",
    "    [['description_no_numbers_v2']].iloc[\n",
    "        30\n",
    "    ].values[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a regex to extract all numbers from the description with 10 symbols before and after\n",
    "# save the extracted numbers in txt file, one string per line\n",
    "\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# extract all numbers from the description with 10 symbols before and after\n",
    "# this may be any symbol, not only space\n",
    "def extract_numbers(text):\n",
    "    # numbers = re.findall(r'(?<=.{0,10})\\d+(?=.*)', text) # error: look-behind requires fixed-width pattern\n",
    "    # numbers = re.findall(r'(?<=\\D{0,10})\\d+(?=\\D{0,10})', text) # error: look-behind requires fixed-width pattern\n",
    "    # numbers = re.findall(r'((оклад|плата)\\W{,3}\\d{1,}\\D?\\d{0,}\\D?\\d{0,}\\D)', text)\n",
    "    # numbers = re.findall(r'((оклад|плата)\\W{,3}\\d[\\d|\\W]+\\d)\\D', text)\n",
    "    # numbers = re.findall(r'((оклад|плата|от)\\W{,3}\\d[\\d|\\W]+\\d)(?![\\s%])', text, re.IGNORECASE)\n",
    "    # pattern = r'((оклад|плата|от)\\W{,3}\\d[\\d|\\W]+\\d)\\D(?![\\s%])'\n",
    "    pattern = r'((оклад|плата|от)\\W.{15})'\n",
    "    # плата 100.000-110.000 + 6\n",
    "    numbers = re.findall(pattern, text, re.IGNORECASE)\n",
    "    # flatten the list\n",
    "    numbers = [number for number, _ in numbers]\n",
    "\n",
    "    # return ' '.join(numbers)\n",
    "    if len(numbers) == 0:\n",
    "        return set(' ')\n",
    "    return set(numbers)\n",
    "\n",
    "# save the extracted numbers in txt file, one string per line\n",
    "# numbers = df['description'].apply(extract_numbers)\n",
    "numbers = set()\n",
    "for text in df['description_no_numbers_v2']:\n",
    "    numbers.update(extract_numbers(text))\n",
    "# numbers = numbers[numbers.apply(len) > 0]\n",
    "# flatten the list\n",
    "# numbers = np.concatenate(numbers)\n",
    "# remove duplicates\n",
    "# numbers = list(set(numbers))\n",
    "with open('../data/extracted_numbers_v2.txt', 'w') as f:\n",
    "    f.write('\\n'.join(numbers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aккpeдитoванная ИТ-кoмпания, рaбoтаeм c 2006 годa. Пpиглaшaeм выeздного систeмного aдминистрaтopa (начинaющeгo)   Разъeзднaя  рабoта на  личном автомобилe , бензин оплачивaeм пo тoпливной каpте. Обслуживаем компьютеры, принтеры, видеонаблюдение и другое ит-оборудование магазинов Пятерочка, Чижик, Перекресток. Выезд из дома сразу на заявку. В мобильном приложении есть перечень заявок со сроками и приоритетами. Район обслуживания: Мацеста, Хоста, Адлер   Оклад [NUMBER] рублей  на руки, оформление по договору ГПХ, с  премией 90-110 тыс   График работы гибкий. 1 плавающий выходной   Разъeзднaя рабoта на личном автомобилe, бензин оплачивaeм пo тoпливной каpте   Bыдaем: ноутбук, инстpумeнт.   Бeз опытa  paбoты с торговым и кассовым оборудованием, есть обучение, полная зарплата с первого дня   Обязателен опыт работы (даже на уверенном бытовом уровне )либо в :   настройке ПК,ПО   ПК железе   работе с проводами (например протянуть домой самому интернет)   установить, наладить подключить доп.оборудование (принтер, МФУ и пр)   Оплачивaем мoбильную связь.   Задачи :     Развозка расходных материалов, картриджей для принтеров по магазинам   Базовая настройка компьютеров по инструкции     Требования : желание учиться и работать в ИТ   Рассматриваем кандидатов, как без  опыта работы , так и с опытом по специальностям: системный администратор, сисадмин, специалист технической поддержки, монтажник слаботочных систем, техник подключения к интернет, техник по обслуживанию компьютеров, ИТ-инженер, сетевой инженер, мобильный сервисный инженер, инженер по инфраструктурным проектам   Подработку, совмещение, временное трудоустройство  не рассматриваем    \n"
     ]
    }
   ],
   "source": [
    "print(df[df['description_no_numbers'].str.contains(\"Пятерочка, Чижик, Перекресток. Выезд \", case=False,regex=False)].description_no_numbers_v2.iloc[0]\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22224 entries, 0 to 22223\n",
      "Data columns (total 15 columns):\n",
      " #   Column                                Non-Null Count  Dtype  \n",
      "---  ------                                --------------  -----  \n",
      " 0   title                                 22224 non-null  object \n",
      " 1   company                               22224 non-null  object \n",
      " 2   location                              22224 non-null  object \n",
      " 3   skills                                14384 non-null  object \n",
      " 4   source                                22224 non-null  object \n",
      " 5   description_no_numbers_with_skills    22224 non-null  object \n",
      " 6   experience_from                       22224 non-null  float64\n",
      " 7   experience_to_adjusted_10             22224 non-null  float64\n",
      " 8   description_size                      22224 non-null  int64  \n",
      " 9   description                           22224 non-null  object \n",
      " 10  description_no_numbers                22224 non-null  object \n",
      " 11  description_no_numbers_v2             22224 non-null  object \n",
      " 12  title_company_location_skills_source  22224 non-null  object \n",
      " 13  salary_from                           22224 non-null  float64\n",
      " 14  log_salary_from                       22224 non-null  float64\n",
      "dtypes: float64(4), int64(1), object(10)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  0   title                                 22224 non-null  object \n",
    "#  1   company                               22224 non-null  object \n",
    "#  2   location                              22224 non-null  object \n",
    "#  3   skills                                22224 non-null  object \n",
    "#  4   source                                22224 non-null  object \n",
    "#  5   description_no_numbers_with_skills    22224 non-null  object \n",
    "#  6   experience_from                       22224 non-null  float64\n",
    "#  7   experience_to_adjusted_10             22224 non-null  float64\n",
    "#  8   description_size                      22224 non-null  int64  \n",
    "#  9   description                           22224 non-null  object \n",
    "#  10  description_no_numbers                22224 non-null  object \n",
    "#  11  title_company_location_skills_source  22224 non-null  object \n",
    "#  12  salary_from                           22224 non-null  float64\n",
    "#  13  log_salary_from                       22224 non-null  float64\n",
    "#  14  description_no_numbers_v2             22224 non-null  object \n",
    "\n",
    "# place col 14 after col 10\n",
    "df = df[['title', 'company', 'location', 'skills', 'source', # for catboost\n",
    "         'description_no_numbers_with_skills', 'experience_from', # for catboost\n",
    "         'experience_to_adjusted_10', 'description_size', # for catboost\n",
    "         'description', # for eda\n",
    "         'description_no_numbers', 'description_no_numbers_v2', 'title_company_location_skills_source', # for transformers\n",
    "         'salary_from', 'log_salary_from' # targets\n",
    "         ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['title',\n",
       " 'company',\n",
       " 'location',\n",
       " 'skills',\n",
       " 'source',\n",
       " 'description_no_numbers_with_skills',\n",
       " 'experience_from',\n",
       " 'experience_to_adjusted_10',\n",
       " 'description_size',\n",
       " 'description',\n",
       " 'description_no_numbers',\n",
       " 'description_no_numbers_v2',\n",
       " 'title_company_location_skills_source',\n",
       " 'salary_from',\n",
       " 'log_salary_from']"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list columns as strings:\n",
    "lst = df.columns.tolist()\n",
    "lst = list(map(str, lst))\n",
    "lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/getmatch_hh_combined_catboost_transformer_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../data/getmatch_hh_combined_catboost_transformer_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22224 entries, 0 to 22223\n",
      "Data columns (total 15 columns):\n",
      " #   Column                                Non-Null Count  Dtype  \n",
      "---  ------                                --------------  -----  \n",
      " 0   title                                 22224 non-null  object \n",
      " 1   company                               22224 non-null  object \n",
      " 2   location                              22224 non-null  object \n",
      " 3   skills                                14384 non-null  object \n",
      " 4   source                                22224 non-null  object \n",
      " 5   description_no_numbers_with_skills    22224 non-null  object \n",
      " 6   experience_from                       22224 non-null  float64\n",
      " 7   experience_to_adjusted_10             22224 non-null  float64\n",
      " 8   description_size                      22224 non-null  int64  \n",
      " 9   description                           22224 non-null  object \n",
      " 10  description_no_numbers                22224 non-null  object \n",
      " 11  description_no_numbers_v2             22224 non-null  object \n",
      " 12  title_company_location_skills_source  22224 non-null  object \n",
      " 13  salary_from                           22224 non-null  float64\n",
      " 14  log_salary_from                       22224 non-null  float64\n",
      "dtypes: float64(4), int64(1), object(10)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add salary bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   log_salary_from  salary_bin\n",
      "0         5.393628           8\n",
      "1         5.521461           8\n",
      "2         5.991465           9\n",
      "3         5.010635           7\n",
      "4         5.010635           7\n",
      "salary_bin\n",
      "0        2\n",
      "1       22\n",
      "2      117\n",
      "3      679\n",
      "4     3805\n",
      "5     6153\n",
      "6     4667\n",
      "7     4451\n",
      "8     1888\n",
      "9      417\n",
      "10      17\n",
      "11       5\n",
      "14       1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Compute bin edges for 15 equal bins\n",
    "num_bins = 15\n",
    "bin_edges = np.linspace(\n",
    "    df[\"log_salary_from\"].min(), df[\"log_salary_from\"].max(), num_bins + 1\n",
    ")\n",
    "\n",
    "# Assign bins to a new column\n",
    "df[\"salary_bin\"] = np.digitize(df[\"log_salary_from\"], bins=bin_edges, right=True) - 1\n",
    "\n",
    "# Ensure bin labels are within range\n",
    "df[\"salary_bin\"] = df[\"salary_bin\"].clip(0, num_bins - 1)\n",
    "\n",
    "print(df[['log_salary_from', 'salary_bin']].head())\n",
    "print(df['salary_bin'].value_counts().sort_index())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add a MASK prompt to the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Далее указано описание вакансии. Судя по описанию, зарплата на этой позиции составляет [MASK].[SEP]Путешествия — онлайн-тревел-агентство в экосистеме компании. Мы построили сервис по продаже авиабилетов с нуля и постоянно развиваем его. Наши клиенты могут бронировать авиабилеты, отели, подбирать онлайн-туры и покупать страховку. Все это можно сделать на удобной площадке: в приложении или на сайте.\n",
      "Аналитик в Путешествиях — не калькулятор в руках продакт-менеджера, а полноценный компаньон и участник разработки продукта.\n",
      "Вот как мы работаем\n",
      "Участвуем во всех процессах discovery, ищем точки роста и влияем на продукт. Мы помогаем определять вектор развития команды, ее метрики и долгосрочные цели, а еще предлагаем идеи улучшения продукта, основываясь на данных.\n",
      "Дизайним и анализируем эксперименты. У нас развитая культура тестирования и своя A/B-платформа: все фичи проходят через эксперименты, ничего не выкатывается «на глаз».\n",
      "Создаем дашборды и аналитические инструменты. Есть четкий процесс создания дашборда, навигатор отчетов, библиотека метрик.\n",
      "Участвуем в общеаналитических проектах. Например, развиваем discovery в компании вместе с коллегами-аналитиками или создаем единую систему инструментария и развиваем Data Driven-культуру в рамках проекта Data Informed.\n",
      "Мы тесно интегрированы со всеми нефинансовыми сервисами, проводим обучающие встречи, устраиваем аналитические тусовки — официальные и неформальные, выступаем на митапах.\n",
      "В команду ждем\n",
      "аналитика\n",
      ", который хочет расти, реализовываться и влиять на бизнес вместе с компанией талантливых коллег.\n",
      "Что предстоит делать\n",
      "Выстраивать систему метрик в продукте.\n",
      "Анализировать продуктовые фичи и гипотезы.\n",
      "Проводить А/В-тесты.\n",
      "Исследовать поведение пользователей, находить проблемы и точки роста.\n",
      "Выступать партнером продуктовых команд при принятии решений на основе данных.\n",
      "Принимать участие в формировании и приоритизации продуктовых планов на основе проведенных исследований.\n",
      "Создавать дашборды и инструменты аналитики — мы используем Tableau и Superset.\n",
      "Мы ждем, что вы\n",
      "Имеете опыт работы в роли продуктового аналитика от года.\n",
      "Имеете опыт дизайна и подведения итогов А/В-тестов.\n",
      "Имеете опыт построения дашбордов в любой BI-системе.\n",
      "Знаете основы математической статистики и теории вероятностей.\n",
      "Знаете принципы работы реляционных баз данных и владеете SQL на хорошем уровне.\n",
      "Умеете видеть за числами действия реальных пользователей и объяснять, почему изменилось их поведение.\n",
      "Проактивно подходите к решению задач: способны самостоятельно разобраться в ситуации, задать правильные вопросы, собрать информацию и сделать выводы, которые приведут к принятию наилучшего решения.\n",
      "Мы предлагаем\n",
      "Работу в офисе или удаленно — по договоренности.\n",
      "Платформу обучения и развития «Апгрейд». Курсы, тренинги, вебинары и базы знаний. Поддержку менторов и наставников, помощь в поиске точек роста и карьерном развитии.\n",
      "Комплексную программу заботы о здоровье. Оформим полис ДМС с широким покрытием и страховку от несчастных случаев. Предложим льготные условия страхования для ваших близких.\n",
      "Возможность работы в аккредитованной ИТ-компании.\n",
      "Линейку льготных тарифов на продукты Т-Банка.\n",
      "Частичную компенсацию затрат на спорт.\n",
      "Well-being программу, которая помогает улучшить психологическое и физическое здоровье, а также разобраться с юридическими и финансовыми вопросами.\n",
      "Три дополнительных дня отпуска в год.\n",
      "Достойную зарплату — обсудим ее на собеседовании.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\\\n",
    "Далее указано описание вакансии. \\\n",
    "Судя по описанию, зарплата на этой позиции составляет [MASK].[SEP]\\\n",
    "\"\"\"\n",
    "\n",
    "df['description_no_numbers_v2_with_prompt'] = prompt + df['description_no_numbers_v2']\n",
    "print(df['description_no_numbers_v2_with_prompt'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create 15 special bin tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([    2, 29213, 36085, 25137, 55184,    18, 35631,   705, 56328,    16,\n",
      "        39099,   548,  4884, 12136,  4432,     4,    18,     3, 53790, 10327,\n",
      "            1, 24965,    17, 32283,  2663,    17, 32040,   314, 45411,  3277,\n",
      "         7197,    18, 19712, 38664, 32827,   705, 32941, 77713,   329, 37934,\n",
      "          320, 15869, 29946,  2156,  1142,    18,     0,     0,     0,     0])\n",
      "tensor([    2, 29213, 36085, 25137, 55184,    18, 35631,   705, 56328,    16,\n",
      "        39099,   548,  4884, 12136,  4432,    63,    38,  8544,    67,    20,\n",
      "           65,    18,     3, 53790, 10327,     1, 24965,    17, 32283,  2663,\n",
      "           17, 32040,   314, 45411,  3277,  7197,    18, 19712, 38664, 32827,\n",
      "          705, 32941, 77713,   329, 37934,   320, 15869, 29946,  2156,  1142])\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# model = SentenceTransformer('sergeyzh/rubert-tiny-turbo')\n",
    "tokenizer = AutoTokenizer.from_pretrained('sergeyzh/rubert-tiny-turbo')\n",
    "\n",
    "sentence = \"\"\"\\\n",
    "Путешествия — онлайн-тревел-агентство в экосистеме компании. \\\n",
    "Мы построили сервис по продаже авиабилетов с нуля и постоянно развиваем его. \\\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "prompt = \"\"\"\\\n",
    "[CLS] Далее указано описание вакансии. \\\n",
    "Судя по описанию, зарплата на этой позиции составляет [MASK].[SEP]\\\n",
    "\"\"\"\n",
    "\n",
    "out = tokenizer(\n",
    "    prompt + sentence,\n",
    "            max_length=None,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "            add_special_tokens=False\n",
    "            )\n",
    "print(out['input_ids'][0][:50])\n",
    "\n",
    "prompt_bin = \"\"\"\\\n",
    "[CLS] Далее указано описание вакансии. \\\n",
    "Судя по описанию, зарплата на этой позиции составляет [BIN_0].[SEP]\\\n",
    "\"\"\"\n",
    "\n",
    "out = tokenizer(\n",
    "    prompt_bin + sentence,\n",
    "            max_length=None,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "            add_special_tokens=False\n",
    "            )\n",
    "print(out['input_ids'][0][:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([    2, 29213, 44916,   721, 25137, 55184,    18, 35631,   705, 13064,\n",
      "        56328,    16, 39099,   548, 22787, 12136,  4432,     4,    18,     3,\n",
      "        53790, 10327,     1, 24965,    17, 32283,  2663,    17, 32040,   314,\n",
      "        45411,  3277,  7197,    18, 19712, 38664, 32827,   705, 32941, 77713,\n",
      "          329, 37934,   320, 15869, 29946,  2156,  1142,    18,     0,     0])\n",
      "(tensor([17]),)\n",
      "tensor([    2, 29213, 44916,   721, 25137, 55184,    18, 35631,   705, 13064,\n",
      "        56328,    16, 39099,   548, 22787, 12136])\n",
      "tensor([    2, 29213, 44916,   721, 25137, 55184,    18, 35631,   705, 13064,\n",
      "        56328,    16, 39099,   548, 22787, 12136,  4432, 83828,    18,     3,\n",
      "        53790, 10327,     1, 24965,    17, 32283,  2663,    17, 32040,   314,\n",
      "        45411,  3277,  7197,    18, 19712, 38664, 32827,   705, 32941, 77713,\n",
      "          329, 37934,   320, 15869, 29946,  2156,  1142,    18,     0,     0])\n",
      "83828\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# model = SentenceTransformer('sergeyzh/rubert-tiny-turbo')\n",
    "tokenizer = AutoTokenizer.from_pretrained('sergeyzh/rubert-tiny-turbo')\n",
    "\n",
    "new_tokens = [f\"[BIN_{i}]\" for i in range(15)]\n",
    "\n",
    "tokenizer.add_tokens(new_tokens)\n",
    "\n",
    "sentence = \"\"\"\\\n",
    "Путешествия — онлайн-тревел-агентство в экосистеме компании. \\\n",
    "Мы построили сервис по продаже авиабилетов с нуля и постоянно развиваем его. \\\n",
    "\"\"\"\n",
    "# sentence = ''\n",
    "\n",
    "prompt = \"\"\"\\\n",
    "[CLS] Далее приведено описание вакансии. \\\n",
    "Судя по этому описанию, зарплата на данной позиции составляет [MASK]. [SEP]\\\n",
    "\"\"\"\n",
    "\n",
    "out = tokenizer(\n",
    "    prompt + sentence,\n",
    "            max_length=None,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "            add_special_tokens=False\n",
    "            )\n",
    "print(out['input_ids'][0][:50])\n",
    "print((out['input_ids'][0] == 4).nonzero(as_tuple=True))\n",
    "print(out['input_ids'][0][:16])\n",
    "\n",
    "prompt_bin = \"\"\"\\\n",
    "[CLS] Далее приведено описание вакансии. \\\n",
    "Судя по этому описанию, зарплата на данной позиции составляет [BIN_0]. [SEP]\\\n",
    "\"\"\"\n",
    "\n",
    "out = tokenizer(\n",
    "    prompt_bin + sentence,\n",
    "            max_length=None,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "            add_special_tokens=False\n",
    "            )\n",
    "print(out['input_ids'][0][:50])\n",
    "\n",
    "print(tokenizer.convert_tokens_to_ids(\"[BIN_0]\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "436507ce74b24c4aad7c829fc2af8be3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/712 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b8619e8b9f0433aaa9bf3b0d9af7f5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/117M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(83843, 312, padding_idx=0)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "bert1 = AutoModel.from_pretrained('sergeyzh/rubert-tiny-turbo')\n",
    "bert1.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([312])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "bert1.embeddings.word_embeddings(torch.tensor(83842)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a snippet to get distribution of number of words in each sentence in the description_no_numbers_v2 column\n",
    "# create a df of unique sentences and their lengths and save it to csv\n",
    "\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# get distribution of number of words in each sentence in the description_no_numbers_v2 column\n",
    "def get_sentence_lengths(text):\n",
    "    # pattern = r'(?<=[.!?])\\s+'\n",
    "    pattern = r'(?<=[.!?])'\n",
    "    sentences = re.split(pattern, text)\n",
    "    # remove empty strings\n",
    "    sentences = [sentence for sentence in sentences if len(sentence) > 0]\n",
    "    # get number of words in each sentence\n",
    "    sentence_lengths = [len(sentence.split()) for sentence in sentences]\n",
    "    return sentences, sentence_lengths\n",
    "\n",
    "# create pd df of unique sentences and their lengths\n",
    "unique_sentences = []\n",
    "unique_sentence_lengths = []\n",
    "for text in df['description_no_numbers_v2']:\n",
    "    sentences, sentence_lengths = get_sentence_lengths(text)\n",
    "    unique_sentences.extend(sentences)\n",
    "    unique_sentence_lengths.extend(sentence_lengths)\n",
    "\n",
    "unique_sentences_df = pd.DataFrame({\n",
    "    'sentence': unique_sentences,\n",
    "    'length': unique_sentence_lengths\n",
    "})\n",
    "\n",
    "# save the df to csv\n",
    "unique_sentences_df.to_csv('../data/unique_sentences.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 287463 entries, 0 to 287462\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   sentence  287463 non-null  object\n",
      " 1   length    287463 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 4.4+ MB\n"
     ]
    }
   ],
   "source": [
    "unique_sentences_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    287463.000000\n",
      "mean         16.792039\n",
      "std          22.371987\n",
      "min           0.000000\n",
      "1%            0.000000\n",
      "5%            1.000000\n",
      "50%          10.000000\n",
      "90%          38.000000\n",
      "95%          58.000000\n",
      "99%         113.000000\n",
      "max         667.000000\n",
      "Name: length, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Number of words in each sentence'}>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get distribution of number of words in each sentence\n",
    "unique_sentence_lengths = unique_sentences_df['length']\n",
    "print(unique_sentence_lengths.describe(percentiles=[0.5, 0.9, 0.05, 0.01, 0.95, 0.99]))\n",
    "\n",
    "# plot the histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title('Number of words in each sentence')\n",
    "unique_sentence_lengths[unique_sentence_lengths < 150].hist(bins=50)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обязанности:   Техническое сопровождение оперативной эксплуатации оборудования связи и телекоммуникаций ГЭС:   - обходы и осмотры оборудования связи и телекоммуникаций ГЭС - контроль технического состояния оборудования связи и телекоммуникаций ГЭС в соответствии с заданным режимом работы - пересмотр технологических схем и инструкций по эксплуатации оборудования связи и телекоммуникаций ГЭС - контроль и учет неисправностей оборудования связи и телекоммуникаций ГЭС в процессе эксплуатации - разработка технических решений по исключению случаев неисправности оборудования связи и телекоммуникаций ГЭС и повышению надежности его работы при дальнейшей эксплуатации - устранение замечаний по результатам проверок инспектирующих и надзорных органов, обследований, заключений проектных организаций, независимых экспертов   Техническое обслуживание оборудования связи и телекоммуникаций ГЭС:   - подготовка предложений при формировании графика отключений оборудования ГЭС - составление рабочих программ вывода оборудования связи и телекоммуникаций ГЭС для технического обслуживания и ввода его в работу - вывод оборудования связи и телекоммуникаций ГЭС и допуск работников к производству работ - выполнение мероприятий по предотвращению ошибочного включения (отключения работающих) оборудования и устройств ГЭС - ввод в работу и проверка работы оборудования связи и телекоммуникаций ГЭС - контроль выполнения работ сторонними организациями, применяемых технологий производства работ и соблюдения требований безопасности - приемка состава и объема выполненных работ в рамках своей зоны ответственности - устранение дефектов и повреждений, ликвидация аварийного состояния оборудования связи и телекоммуникаций ГЭС   Решение производственно-технических задач по сопровождению эксплуатации оборудования связи и телекоммуникаций ГЭС:   - контроль технического состояния оборудования связи и телекоммуникаций ГЭС в соответствии с заданным режимом работы - контроль и учет неисправностей оборудования связи и телекоммуникаций ГЭС в процессе эксплуатации - сбор данных о дефектах, выявленных в процессе эксплуатации оборудования связи и телекоммуникаций ГЭС - сбор информации о работе оборудования связи и телекоммуникаций ГЭС при авариях и нарушениях нормального режима работы - анализ дефектов, выявленных в процессе эксплуатации оборудования связи и телекоммуникаций ГЭС - анализ работы оборудования связи и телекоммуникаций ГЭС при авариях и нарушениях нормального режима работы - фиксация результатов анализа работы оборудования связи и телекоммуникаций ГЭС в специализированных информационных программах и формах отчетности - разработка технических решений по исключению случаев неисправности оборудования связи и телекоммуникаций ГЭС и повышению надежности его работы при дальнейшей эксплуатации   Решение производственно-технических задач по техническому обслуживанию оборудования связи и телекоммуникаций ГЭС:   - разработка программ и графиков технического обслуживания оборудования связи и телекоммуникаций ГЭС - внесение предложений при разработке документов, регламентирующих периодичность и объемы технического обслуживания оборудования связи и телекоммуникаций ГЭС - составление типовых программ вывода для технического обслуживания и ввода в работу оборудования связи и телекоммуникаций ГЭС - внесение предложений при составлении графиков ремонта единиц основного оборудования - надзор за применяемыми технологиями производства работ и соблюдением правил безопасности - приемка состава и объема выполненных работ в рамках выделенной зоны ответственности   Требования:   Высшее образование – бакалавриат, направления: «Радиотехника», «Инфокоммуникационные технологии и системы связи», «Электроэнергетика и электротехника» Стаж работы по направлению деятельности по эксплуатации и обслуживанию оборудования связи и телекоммуникаций - желателен Особые условия допуска к работе: наличие III группы по электробезопасности - желательно   Знания и навыки:   - ведение технической документации по эксплуатации оборудования связи и телекоммуникаций ГЭС - применение специальных диагностических приборов и оборудования для определения технического состояния оборудования связи - проверка функционирования сети связи после восстановления и ввода в эксплуатацию - оформление производственной, оперативной документации по эксплуатации оборудования связи и телекоммуникаций ГЭС - работа со специализированными программами на уровне пользователя - инструкции по эксплуатации закрепленного оборудования связи и телекоммуникаций ГЭС - места расположения аппаратуры участка - требования охраны труда, промышленной и пожарной безопасности, производственной санитарии и противопожарной защиты, регламентирующие деятельность по трудовой функции - правила применения и испытания защитных средств, применяемых в электроустановках - правила технического обслуживания коммутационного оборудования - требования к технической эксплуатации электрических станций и сетей - схемы организации и прохождения каналов связи ГЭС - схемы организации электропитания коммутационной аппаратуры от источников переменного и постоянного тока, в нормальном и аварийном режимах - схемы электропитания узла связи и алгоритм действий при различного рода переключениях - правила безопасности при работе с инструментом и приспособлениями - требования к правилам работы с персоналом в организациях электроэнергетики - правила технического обслуживания коммутационного оборудования связи и телекоммуникаций ГЭC - навык работы на компьютере: уверенный пользователь Microsoft Office (Word.\n"
     ]
    }
   ],
   "source": [
    "print(unique_sentences_df[unique_sentences_df.length == unique_sentences_df.length.max()].sentence.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    2385.000000\n",
      "mean       17.594969\n",
      "std        24.300713\n",
      "min         0.000000\n",
      "1%          0.000000\n",
      "5%          1.000000\n",
      "50%        11.000000\n",
      "90%        40.000000\n",
      "95%        59.800000\n",
      "99%       108.160000\n",
      "max       350.000000\n",
      "Name: length, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Number of words in each sentence'}>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split df to get the first 80%\n",
    "df_short, _ = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Further split df_short to get 10% of it\n",
    "df_short, _ = train_test_split(df_short, test_size=0.99, random_state=42)\n",
    "\n",
    "# Create a DataFrame of unique sentences and their lengths for df_short\n",
    "unique_sentences = []\n",
    "unique_sentence_lengths = []\n",
    "for text in df_short['description_no_numbers_v2']:\n",
    "    sentences, sentence_lengths = get_sentence_lengths(text)\n",
    "    unique_sentences.extend(sentences)\n",
    "    unique_sentence_lengths.extend(sentence_lengths)\n",
    "\n",
    "unique_sentences_df = pd.DataFrame({\n",
    "    'sentence': unique_sentences,\n",
    "    'length': unique_sentence_lengths\n",
    "})\n",
    "\n",
    "# Save the DataFrame to CSV\n",
    "unique_sentences_df.to_csv('../data/unique_sentences.csv', index=False)\n",
    "\n",
    "# get distribution of number of words in each sentence\n",
    "unique_sentence_lengths = unique_sentences_df['length']\n",
    "print(unique_sentence_lengths.describe(percentiles=[0.5, 0.9, 0.05, 0.01, 0.95, 0.99]))\n",
    "\n",
    "# plot the histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title('Number of words in each sentence')\n",
    "unique_sentence_lengths[unique_sentence_lengths < 150].hist(bins=50)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1193\n"
     ]
    }
   ],
   "source": [
    "print(unique_sentence_lengths[(unique_sentence_lengths >= 10) & (unique_sentence_lengths <= 60)].shape[0])\n",
    "# unique_sentences = unique_sentences_df[(unique_sentences_df.length >= 20) & (unique_sentences_df.length <= 60)]['sentence']\n",
    "# print(len(unique_sentences.tolist()))\n",
    "# print(unique_sentences.tolist()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17690, 89, 4445)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_col_1 = 'description_no_numbers_v2'\n",
    "text_col_2 = 'title_company_location_skills_source'\n",
    "X = df[[text_col_1, text_col_2]]\n",
    "y = df['log_salary_from']\n",
    "# Split\n",
    "SEED = 42\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)\n",
    "X_train, X_tsdae, y_train, y_tsdae = train_test_split(X_train, y_train, test_size=0.005, random_state=SEED)\n",
    "len(X_train), len(X_tsdae), len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now write a snippet that, given a df, creates a set of sentences from description_no_numbers_v2 column\n",
    "# and creates pd dataframe with sentence per row. use get_sentence\n",
    "\n",
    "sentences = df['description_no_numbers_v2'][:200].apply(get_sentences)\n",
    "sentences = np.concatenate(sentences)\n",
    "sentences = pd.DataFrame(sentences, columns=['sentence'])\n",
    "sentences.to_csv('../data/sentences.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Embeddings from pre-trained transformers + MLP, combine (or not) with catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code from task 2 to be adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppress all FutureWarnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "import random\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def average_pool(last_hidden_states: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:\n",
    "    last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
    "    return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
    "\n",
    "\n",
    "# Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0]  # First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    return sum_embeddings / sum_mask\n",
    "\n",
    "\n",
    "def pool(hidden_state, mask, pooling_method=\"cls\"):\n",
    "    if pooling_method == \"mean\":\n",
    "        s = torch.sum(hidden_state * mask.unsqueeze(-1).float(), dim=1)\n",
    "        d = mask.sum(axis=1, keepdim=True).float()\n",
    "        return s / d\n",
    "    elif pooling_method == \"cls\":\n",
    "        return hidden_state[:, 0]\n",
    "\n",
    "\n",
    "# Set the seed\n",
    "set_seed(42)\n",
    "model_name = \"sismetanin/sbert-ru-sentiment-rureviews\"\n",
    "# Load AutoModel from huggingface model repository\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"ai-forever/sbert_large_nlu_ru\")\n",
    "# model = AutoModel.from_pretrained(\"ai-forever/sbert_large_nlu_ru\")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"ai-forever/ru-en-RoSBERTa\")\n",
    "# model = AutoModel.from_pretrained(\"ai-forever/ru-en-RoSBERTa\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"deepvk/USER-bge-m3\")\n",
    "# model = AutoModel.from_pretrained(\"deepvk/USER-bge-m3\")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"intfloat/multilingual-e5-large-instruct\")\n",
    "# model = AutoModel.from_pretrained(\"intfloat/multilingual-e5-large-instruct\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Check if multiple GPUs are available and use DataParallel\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = torch.nn.DataParallel(model, device_ids=[0, 1])\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# Create dataset and dataloader\n",
    "class FiveDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_seq_len):\n",
    "        self.data = dataframe\n",
    "        self.text = dataframe['text'].tolist()\n",
    "        # self.text = dataframe['text_with_instruct'].tolist()\n",
    "        self.targets = dataframe['rate'].tolist() if 'rate' in dataframe else None\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_seq_len = max_seq_len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.text[index])\n",
    "        # text = ' '.join(text.split())\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_seq_len,\n",
    "            padding='max_length',\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        if self.targets is not None:\n",
    "            return {\n",
    "                'input_ids': torch.tensor(ids, dtype=torch.long),\n",
    "                'attention_mask': torch.tensor(mask, dtype=torch.long),\n",
    "                'targets': torch.tensor(self.targets[index], dtype=torch.long)\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                'input_ids': torch.tensor(ids, dtype=torch.long),\n",
    "                'attention_mask': torch.tensor(mask, dtype=torch.long),\n",
    "            }\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.text)\n",
    "\n",
    "# Assuming train_split, val_split, and test_data are already defined\n",
    "# train_dataset = FiveDataset(train_data_no_duplicates, tokenizer, MAX_LEN)\n",
    "train_dataset = FiveDataset(train_data, tokenizer, MAX_LEN)\n",
    "test_dataset = FiveDataset(test_data, tokenizer, MAX_LEN)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Function to compute and save pooled embeddings\n",
    "def compute_and_save_embeddings(dataloader, model, device):\n",
    "    embeddings = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            pooled_embeddings = mean_pooling(outputs, attention_mask)  # Ensure attention_mask is on the same device\n",
    "            cls_embeddings = outputs[0][:, 0]\n",
    "            pooled_embeddings = torch.cat((pooled_embeddings, cls_embeddings), 1)\n",
    "            \n",
    "            # pooled_embeddings = pool(outputs.last_hidden_state, attention_mask)  # Ensure attention_mask is on the same device\n",
    "            # pooled_embeddings = outputs[0][:, 0]\n",
    "            # pooled_embeddings = average_pool(outputs.last_hidden_state, attention_mask)  # Ensure attention_mask is on the same device\n",
    "            \n",
    "            embeddings.append(pooled_embeddings.cpu().numpy())\n",
    "            if 'targets' in batch:\n",
    "                labels.append(batch['targets'].cpu().numpy())\n",
    "    embeddings = np.vstack(embeddings)\n",
    "    labels = np.hstack(labels) if labels else None\n",
    "    return embeddings, labels\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# name = 'e5_instr_en_full'\n",
    "# name = 'USER-bge-m3_full'\n",
    "model_name = model_name.replace('/', '_')\n",
    "train_embeddings, train_labels = compute_and_save_embeddings(train_dataloader, model, device)\n",
    "np.save(f'train_embeddings_{model_name}.npy', train_embeddings)\n",
    "np.save(f'train_labels_{model_name}.npy', train_labels)\n",
    "test_embeddings, test_labels = compute_and_save_embeddings(test_dataloader, model, device)\n",
    "\n",
    "# Save embeddings and labels\n",
    "np.save(f'test_embeddings_{model_name}.npy', test_embeddings)\n",
    "np.save(f'test_labels_{model_name}.npy', test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code by GPT for this task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39ed1d07bf174695a9114260e4c14989",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c287b1dc76b64ed5bf6d9870ea3ddb90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "812a1249dead4c9299b62e5304fc4f81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f46b7ae2d77e44b98f2988eed4cf413e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/964 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fcbddf5207547a6af83106ba38f7041",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/690 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97417c0e4cf1478ca0d696ab7b2f7377",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[246], line 70\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# Load tokenizer and model\u001b[39;00m\n\u001b[1;32m     69\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n\u001b[0;32m---> 70\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     72\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/miniconda3/envs/ods-final-project-salary/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:564\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    563\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    570\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/ods-final-project-salary/lib/python3.11/site-packages/transformers/modeling_utils.py:3825\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3809\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   3810\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[1;32m   3811\u001b[0m     cached_file_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   3812\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcache_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m: cache_dir,\n\u001b[1;32m   3813\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforce_download\u001b[39m\u001b[38;5;124m\"\u001b[39m: force_download,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3823\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m: commit_hash,\n\u001b[1;32m   3824\u001b[0m     }\n\u001b[0;32m-> 3825\u001b[0m     resolved_archive_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcached_file_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3827\u001b[0m     \u001b[38;5;66;03m# Since we set _raise_exceptions_for_missing_entries=False, we don't get an exception but a None\u001b[39;00m\n\u001b[1;32m   3828\u001b[0m     \u001b[38;5;66;03m# result when internet is up, the repo and revision exist, but the file does not.\u001b[39;00m\n\u001b[1;32m   3829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m resolved_archive_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m filename \u001b[38;5;241m==\u001b[39m _add_variant(SAFE_WEIGHTS_NAME, variant):\n\u001b[1;32m   3830\u001b[0m         \u001b[38;5;66;03m# Maybe the checkpoint is sharded, we try to grab the index name in this case.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ods-final-project-salary/lib/python3.11/site-packages/transformers/utils/hub.py:403\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    400\u001b[0m user_agent \u001b[38;5;241m=\u001b[39m http_user_agent(user_agent)\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 403\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    418\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m _get_cache_file_to_return(path_or_repo_id, full_filename, cache_dir, revision)\n",
      "File \u001b[0;32m~/miniconda3/envs/ods-final-project-salary/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ods-final-project-salary/lib/python3.11/site-packages/huggingface_hub/file_download.py:862\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m    842\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_local_dir(\n\u001b[1;32m    843\u001b[0m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[1;32m    844\u001b[0m         local_dir\u001b[38;5;241m=\u001b[39mlocal_dir,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    859\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m    860\u001b[0m     )\n\u001b[1;32m    861\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[1;32m    864\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[1;32m    866\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[1;32m    871\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[1;32m    877\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ods-final-project-salary/lib/python3.11/site-packages/huggingface_hub/file_download.py:1011\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1009\u001b[0m Path(lock_path)\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mmkdir(parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m WeakFileLock(lock_path):\n\u001b[0;32m-> 1011\u001b[0m     \u001b[43m_download_to_tmp_and_move\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[43m        \u001b[49m\u001b[43mincomplete_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.incomplete\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1013\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdestination_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1019\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1021\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(pointer_path):\n\u001b[1;32m   1022\u001b[0m         _create_symlink(blob_path, pointer_path, new_blob\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/ods-final-project-salary/lib/python3.11/site-packages/huggingface_hub/file_download.py:1545\u001b[0m, in \u001b[0;36m_download_to_tmp_and_move\u001b[0;34m(incomplete_path, destination_path, url_to_download, proxies, headers, expected_size, filename, force_download)\u001b[0m\n\u001b[1;32m   1542\u001b[0m         _check_disk_space(expected_size, incomplete_path\u001b[38;5;241m.\u001b[39mparent)\n\u001b[1;32m   1543\u001b[0m         _check_disk_space(expected_size, destination_path\u001b[38;5;241m.\u001b[39mparent)\n\u001b[0;32m-> 1545\u001b[0m     \u001b[43mhttp_get\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1546\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1547\u001b[0m \u001b[43m        \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1548\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1549\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1550\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1552\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1554\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownload complete. Moving file to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdestination_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1555\u001b[0m _chmod_and_move(incomplete_path, destination_path)\n",
      "File \u001b[0;32m~/miniconda3/envs/ods-final-project-salary/lib/python3.11/site-packages/huggingface_hub/file_download.py:454\u001b[0m, in \u001b[0;36mhttp_get\u001b[0;34m(url, temp_file, proxies, resume_size, headers, expected_size, displayed_filename, _nb_retries, _tqdm_bar)\u001b[0m\n\u001b[1;32m    452\u001b[0m new_resume_size \u001b[38;5;241m=\u001b[39m resume_size\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 454\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconstants\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDOWNLOAD_CHUNK_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# filter out keep-alive new chunks\u001b[39;49;00m\n\u001b[1;32m    456\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ods-final-project-salary/lib/python3.11/site-packages/requests/models.py:820\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    819\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 820\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    822\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[0;32m~/miniconda3/envs/ods-final-project-salary/lib/python3.11/site-packages/urllib3/response.py:1060\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m   1058\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1059\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1060\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1062\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[1;32m   1063\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/ods-final-project-salary/lib/python3.11/site-packages/urllib3/response.py:949\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    946\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m amt:\n\u001b[1;32m    947\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer\u001b[38;5;241m.\u001b[39mget(amt)\n\u001b[0;32m--> 949\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    951\u001b[0m flush_decoder \u001b[38;5;241m=\u001b[39m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data)\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/ods-final-project-salary/lib/python3.11/site-packages/urllib3/response.py:873\u001b[0m, in \u001b[0;36mHTTPResponse._raw_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    870\u001b[0m fp_closed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclosed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    872\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_error_catcher():\n\u001b[0;32m--> 873\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    874\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[1;32m    875\u001b[0m         \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[1;32m    876\u001b[0m         \u001b[38;5;66;03m# Close the connection when no data is returned\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[1;32m    883\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniconda3/envs/ods-final-project-salary/lib/python3.11/site-packages/urllib3/response.py:856\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1(amt) \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1()\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m~/miniconda3/envs/ods-final-project-salary/lib/python3.11/http/client.py:473\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[1;32m    472\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[0;32m--> 473\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mread(amt)\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    476\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m~/miniconda3/envs/ods-final-project-salary/lib/python3.11/socket.py:718\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    717\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 718\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    720\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ods-final-project-salary/lib/python3.11/ssl.py:1314\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1310\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1311\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1312\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1313\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/miniconda3/envs/ods-final-project-salary/lib/python3.11/ssl.py:1166\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1166\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1167\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1168\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "# Suppress all FutureWarnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "def set_seed(seed: int) -> None:\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Parameters\n",
    "MAX_LEN = 256  # Maximum sequence length\n",
    "BATCH_SIZE = 32  # Batch size\n",
    "model_name = \"intfloat/multilingual-e5-large-instruct\"\n",
    "\n",
    "\n",
    "# Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0]  # First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    return sum_embeddings / sum_mask\n",
    "\n",
    "# CLS Pooling - Use when only the sentence embedding is needed\n",
    "def cls_pooling(hidden_state, mask) -> torch.Tensor:\n",
    "    return hidden_state[:, 0]\n",
    "\n",
    "\n",
    "# Dataset class\n",
    "class JobDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_seq_len: int, text_column: str):\n",
    "        self.data = dataframe\n",
    "        self.texts = dataframe[text_column].tolist()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_seq_len = max_seq_len\n",
    "\n",
    "    def __getitem__(self, index: int) -> Dict:\n",
    "        text = str(self.texts[index])\n",
    "        inputs = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_seq_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'].squeeze(0),\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(0)\n",
    "        }\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.texts)\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Compute embeddings\n",
    "def compute_embeddings(dataloader: DataLoader, model, device) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    mean_embeddings = []\n",
    "    cls_embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            \n",
    "            # Compute mean and CLS embeddings\n",
    "            mean_emb = mean_pooling(outputs, attention_mask)\n",
    "            cls_emb = cls_pooling(outputs)\n",
    "            \n",
    "            mean_embeddings.append(mean_emb.cpu().numpy())\n",
    "            cls_embeddings.append(cls_emb.cpu().numpy())\n",
    "\n",
    "    return np.vstack(mean_embeddings), np.vstack(cls_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_short = df.sample(100, random_state=42)\n",
    "# Prepare data\n",
    "X = df_short[['description', 'title_company_location_skills_source']]\n",
    "y = df_short['log_salary_from']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# Description embeddings\n",
    "train_description_dataset = JobDataset(X_train, tokenizer, MAX_LEN, text_column='description')\n",
    "test_description_dataset = JobDataset(X_test, tokenizer, MAX_LEN, text_column='description')\n",
    "train_description_loader = DataLoader(train_description_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_description_loader = DataLoader(test_description_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Title+Company+Location+Skills+Source embeddings\n",
    "train_title_dataset = JobDataset(X_train, tokenizer, MAX_LEN, text_column='title_company_location_skills_source')\n",
    "test_title_dataset = JobDataset(X_test, tokenizer, MAX_LEN, text_column='title_company_location_skills_source')\n",
    "train_title_loader = DataLoader(train_title_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_title_loader = DataLoader(test_title_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Compute embeddings\n",
    "train_mean_desc, train_cls_desc = compute_embeddings(train_description_loader, model, device)\n",
    "test_mean_desc, test_cls_desc = compute_embeddings(test_description_loader, model, device)\n",
    "train_mean_title, train_cls_title = compute_embeddings(train_title_loader, model, device)\n",
    "test_mean_title, test_cls_title = compute_embeddings(test_title_loader, model, device)\n",
    "\n",
    "# Combine embeddings\n",
    "train_embeddings = np.hstack([train_mean_desc, train_cls_desc, train_mean_title, train_cls_title])\n",
    "test_embeddings = np.hstack([test_mean_desc, test_cls_desc, test_mean_title, test_cls_title])\n",
    "\n",
    "# Save embeddings\n",
    "np.save('train_embeddings.npy', train_embeddings)\n",
    "np.save('test_embeddings.npy', test_embeddings)\n",
    "np.save('y_train.npy', y_train.values)\n",
    "np.save('y_test.npy', y_test.values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning transformer + MLP head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two berts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data\n",
    "!mkdir models\n",
    "!wget --no-check-certificate 'https://drive.usercontent.google.com/download?id=1_o4xDSF6j95vAiYdd97VavyWq4EHHPdP&export=download&authuser=1&confirm=t' -O './data/dataset.csv'\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv('./data/dataset.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Suppress all FutureWarnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "def set_seed(seed: int) -> None:\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Set the seed\n",
    "SEED = 42\n",
    "set_seed(SEED)\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 16\n",
    "seq_length = 512\n",
    "hidden_size = 768  # BERT base hidden size\n",
    "mlp_hidden_size = 256\n",
    "num_epochs = 10\n",
    "learning_rate = 2e-5\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_name = \"cointegrated/LaBSE-en-ru\"\n",
    "\n",
    "\n",
    "# Dataset for dual textual features\n",
    "class DualTextDataset(Dataset):\n",
    "    def __init__(self, df, text_col_1, text_col_2, targets, tokenizer, max_len):\n",
    "        # Pre-tokenize and store inputs\n",
    "        self.tokenized_texts1 = tokenizer(df[text_col_1].tolist(), max_length=max_len, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "        self.tokenized_texts2 = tokenizer(df[text_col_2].tolist(), max_length=max_len, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "        self.targets = targets.tolist()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Return only the slice for idx\n",
    "        inputs1 = {key: val[idx] for key, val in self.tokenized_texts1.items()}\n",
    "        inputs2 = {key: val[idx] for key, val in self.tokenized_texts2.items()}\n",
    "        target = torch.tensor(self.targets[idx], dtype=torch.float)\n",
    "        return inputs1, inputs2, target\n",
    "\n",
    "# Define the dual BERT model with an MLP head\n",
    "class DualBERTWithMLP(nn.Module):\n",
    "    def __init__(self, hidden_size, mlp_hidden_size):\n",
    "        super(DualBERTWithMLP, self).__init__()\n",
    "        # Initialize two independent BERT models\n",
    "        self.bert1 = AutoModel.from_pretrained(model_name)\n",
    "        self.bert2 = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "        # Define MLP head\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(2 * hidden_size, mlp_hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(mlp_hidden_size, 1)  # Regression output\n",
    "        )\n",
    "\n",
    "    def forward(self, input1, attention_mask1, input2, attention_mask2):\n",
    "        # Forward pass through BERT1\n",
    "        cls1 = self.bert1(input_ids=input1, attention_mask=attention_mask1).last_hidden_state[:, 0, :]  # CLS token\n",
    "        # also get mask token (idx unknown, but token_id is 4)\n",
    "        # mask1 = self.bert1(input_ids=input1, attention_mask=attention_mask1).last_hidden_state[:, 4, :]  # Mask token\n",
    "        # no, because mask token is not always present in the input\n",
    "        mask1 = self.bert1(input_ids=input1, attention_mask=attention_mask1).pooler_output  # Pooler output\n",
    "\n",
    "        # Forward pass through BERT2\n",
    "        cls2 = self.bert2(input_ids=input2, attention_mask=attention_mask2).last_hidden_state[:, 0, :]  # CLS token\n",
    "\n",
    "        # Concatenate CLS embeddings\n",
    "        combined_cls = torch.cat([cls1, cls2], dim=-1)  # Shape: [batch_size, 2 * hidden_size]\n",
    "\n",
    "        # Pass through MLP head\n",
    "        output = self.mlp(combined_cls)\n",
    "        return output\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Dataset and DataLoader\n",
    "# Prepare data\n",
    "text_col_1 = 'description_no_numbers_v2'\n",
    "text_col_2 = 'title_company_location_skills_source'\n",
    "X = df[[text_col_1, text_col_2]]\n",
    "y = df['log_salary_from']\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)\n",
    "\n",
    "# Make datasets\n",
    "train_dataset = DualTextDataset(X_train, text_col_1, text_col_2, y_train, tokenizer, seq_length)\n",
    "test_dataset = DualTextDataset(X_test, text_col_1, text_col_2, y_test, tokenizer, seq_length)\n",
    "# Make dataloaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Initialize the model\n",
    "model = DualBERTWithMLP(hidden_size, mlp_hidden_size)\n",
    "model = torch.nn.DataParallel(model).to(device)\n",
    "\n",
    "# Optimizer and Loss Function\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.MSELoss()  # For regression\n",
    "\n",
    "# Enhanced Training and Evaluation Loop\n",
    "history = {\"train_loss\": [],\n",
    "           \"test_loss\": [], \n",
    "           \"train_r2\": [],\n",
    "           \"test_r2\": [],\n",
    "           \"max_test_r2\": float('-inf'),\n",
    "           \"best_preds\": []\n",
    "           }\n",
    "\n",
    "test_labels = y_test\n",
    "test_preds = []\n",
    "for epoch in range(num_epochs):\n",
    "    # Training Phase\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    for batch in train_dataloader:\n",
    "        inputs1, inputs2, targets = batch\n",
    "        input1 = inputs1[\"input_ids\"].squeeze(1).to(device)\n",
    "        attention_mask1 = inputs1[\"attention_mask\"].squeeze(1).to(device)\n",
    "        input2 = inputs2[\"input_ids\"].squeeze(1).to(device)\n",
    "        attention_mask2 = inputs2[\"attention_mask\"].squeeze(1).to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input1, attention_mask1, input2, attention_mask2)\n",
    "        loss = criterion(outputs.squeeze(), targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_losses.append(loss.item())\n",
    "        all_preds.extend(outputs.squeeze().cpu().detach().numpy())\n",
    "        all_labels.extend(targets.cpu().numpy())\n",
    "\n",
    "    train_loss = np.mean(train_losses)\n",
    "    train_r2 = r2_score(all_labels, all_preds)\n",
    "    history[\"train_loss\"].append(train_loss)\n",
    "    history[\"train_r2\"].append(train_r2)\n",
    "\n",
    "    # Evaluation Phase\n",
    "    model.eval()\n",
    "    test_losses = []\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in test_dataloader:\n",
    "            inputs1, inputs2, targets = batch\n",
    "            input1 = inputs1[\"input_ids\"].squeeze(1).to(device)\n",
    "            attention_mask1 = inputs1[\"attention_mask\"].squeeze(1).to(device)\n",
    "            input2 = inputs2[\"input_ids\"].squeeze(1).to(device)\n",
    "            attention_mask2 = inputs2[\"attention_mask\"].squeeze(1).to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            outputs = model(input1, attention_mask1, input2, attention_mask2)\n",
    "            loss = criterion(outputs.squeeze(), targets)\n",
    "            test_losses.append(loss.item())\n",
    "            all_preds.extend(outputs.squeeze().cpu().numpy())\n",
    "            all_labels.extend(targets.cpu().numpy())\n",
    "\n",
    "    test_loss = np.mean(test_losses)\n",
    "    test_r2 = r2_score(all_labels, all_preds)\n",
    "\n",
    "    history[\"test_loss\"].append(test_loss)\n",
    "    history[\"test_r2\"].append(test_r2)\n",
    "\n",
    "    if test_r2 > history[\"max_test_r2\"]:\n",
    "        history[\"max_test_r2\"] = test_r2\n",
    "        history[\"best_preds\"] = all_preds\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Train R2: {train_r2:.4f}, Test R2: {test_r2:.4f}\")\n",
    "    torch.save(model.state_dict(), f'./models/model_epoch_{epoch + 1}.pth')\n",
    "\n",
    "# Plot Training and Validation Metrics\n",
    "# plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot Loss\n",
    "# plt.subplot(1, 2, 1)\n",
    "plt.plot(history[\"train_loss\"], label=\"Train Loss\")\n",
    "plt.plot(history[\"test_loss\"], label=\"Test Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training and Test Loss Over Epochs\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot R2 Score\n",
    "# plt.subplot(1, 2, 2)\n",
    "plt.plot(history[\"train_r2\"], label=\"Train R2\")\n",
    "plt.plot(history[\"test_r2\"], label=\"Test R2\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"R2 Score\")\n",
    "plt.title(\"Train/Test R2 Score Over Epochs\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# plt.tight_layout()\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), \"./models/final_model.pth\")\n",
    "\n",
    "# save history as pickle\n",
    "import pickle\n",
    "\n",
    "with open('./models/history.pkl', 'wb') as f:\n",
    "    pickle.dump(history, f)\n",
    "\n",
    "# last run:\n",
    "# Epoch 1/10, Train Loss: 0.2170, Test Loss: 0.1120, Test R2: 0.7158\n",
    "# Epoch 2/10, Train Loss: 0.1062, Test Loss: 0.1018, Test R2: 0.7416"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data\n",
    "!mkdir models\n",
    "!wget --no-check-certificate 'https://drive.usercontent.google.com/download?id=1_o4xDSF6j95vAiYdd97VavyWq4EHHPdP&export=download&authuser=1&confirm=t' -O './data/dataset.csv'\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv('./data/dataset.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Suppress all FutureWarnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "def set_seed(seed: int) -> None:\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Set the seed\n",
    "SEED = 42\n",
    "set_seed(SEED)\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 16\n",
    "seq_length = 512\n",
    "hidden_size = 768  # BERT base hidden size\n",
    "mlp_hidden_size = 256\n",
    "num_epochs = 10\n",
    "learning_rate = 2e-5\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_name = \"cointegrated/LaBSE-en-ru\"\n",
    "\n",
    "\n",
    "# Dataset for dual textual features\n",
    "class DualTextDataset(Dataset):\n",
    "    def __init__(self, df, text_col_1, text_col_2, targets, tokenizer, max_len):\n",
    "        # Pre-tokenize and store inputs\n",
    "        self.tokenized_texts1 = tokenizer(df[text_col_1].tolist(), max_length=max_len, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "        self.tokenized_texts2 = tokenizer(df[text_col_2].tolist(), max_length=max_len, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "        self.targets = targets.tolist()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        print(f\"len(self.tokenized_texts1['input_ids']): {len(self.tokenized_texts1['input_ids'])}\")\n",
    "        print(f\"len(self.tokenized_texts2['input_ids']): {len(self.tokenized_texts2['input_ids'])}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Return only the slice for idx\n",
    "        inputs1 = {key: val[idx] for key, val in self.tokenized_texts1.items()}\n",
    "        inputs2 = {key: val[idx] for key, val in self.tokenized_texts2.items()}\n",
    "        target = torch.tensor(self.targets[idx], dtype=torch.float)\n",
    "        return inputs1, inputs2, target\n",
    "\n",
    "\n",
    "class SingleBERTWithMLP(nn.Module):\n",
    "    def __init__(self, hidden_size, mlp_hidden_size):\n",
    "        super(SingleBERTWithMLP, self).__init__()\n",
    "        # Initialize a single BERT model\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "        # Define MLP head\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(2 * hidden_size, mlp_hidden_size),  # Double hidden size for concatenation\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(mlp_hidden_size, 1)  # Regression output\n",
    "        )\n",
    "\n",
    "    def forward(self, input1, attention_mask1, input2, attention_mask2):\n",
    "        # Pass both inputs through the same BERT model\n",
    "        cls1 = self.bert(input_ids=input1, attention_mask=attention_mask1).last_hidden_state[:, 0, :]  # CLS token for input1\n",
    "        cls2 = self.bert(input_ids=input2, attention_mask=attention_mask2).last_hidden_state[:, 0, :]  # CLS token for input2\n",
    "        # get token number 23 from the last hidden state\n",
    "        # token23 = self.bert(input_ids=input1, attention_mask=attention_mask1).last_hidden_state[:, 23, :]  # token 23 for input1\n",
    "\n",
    "        # Concatenate CLS embeddings\n",
    "        combined_cls = torch.cat([cls1, cls2], dim=-1)  # Shape: [batch_size, 2 * hidden_size]\n",
    "\n",
    "        # Pass through MLP head\n",
    "        output = self.mlp(combined_cls)\n",
    "        return output\n",
    "\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Dataset and DataLoader\n",
    "# Prepare data\n",
    "text_col_1 = 'description_no_numbers_v2'\n",
    "text_col_2 = 'title_company_location_skills_source'\n",
    "X = df[[text_col_1, text_col_2]]\n",
    "y = df['log_salary_from']\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)\n",
    "\n",
    "# Make datasets\n",
    "train_dataset = DualTextDataset(X_train, text_col_1, text_col_2, y_train, tokenizer, seq_length)\n",
    "test_dataset = DualTextDataset(X_test, text_col_1, text_col_2, y_test, tokenizer, seq_length)\n",
    "# Make dataloaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Initialize the model\n",
    "model = SingleBERTWithMLP(hidden_size, mlp_hidden_size)\n",
    "model = torch.nn.DataParallel(model).to(device)\n",
    "\n",
    "# Optimizer and Loss Function\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.MSELoss()  # For regression\n",
    "\n",
    "# Enhanced Training and Evaluation Loop\n",
    "history = {\"train_loss\": [],\n",
    "           \"test_loss\": [], \n",
    "           \"train_r2\": [],\n",
    "           \"test_r2\": [],\n",
    "           \"max_test_r2\": float('-inf'),\n",
    "           \"best_preds\": []\n",
    "           }\n",
    "\n",
    "test_labels = y_test\n",
    "test_preds = []\n",
    "for epoch in range(num_epochs):\n",
    "    # Training Phase\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    for batch in train_dataloader:\n",
    "        inputs1, inputs2, targets = batch\n",
    "        input1 = inputs1[\"input_ids\"].squeeze(1).to(device)\n",
    "        attention_mask1 = inputs1[\"attention_mask\"].squeeze(1).to(device)\n",
    "        input2 = inputs2[\"input_ids\"].squeeze(1).to(device)\n",
    "        attention_mask2 = inputs2[\"attention_mask\"].squeeze(1).to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input1, attention_mask1, input2, attention_mask2)\n",
    "        loss = criterion(outputs.squeeze(), targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_losses.append(loss.item())\n",
    "        all_preds.extend(outputs.squeeze().cpu().detach().numpy())\n",
    "        all_labels.extend(targets.cpu().numpy())\n",
    "\n",
    "    train_loss = np.mean(train_losses)\n",
    "    train_r2 = r2_score(all_labels, all_preds)\n",
    "    history[\"train_loss\"].append(train_loss)\n",
    "    history[\"train_r2\"].append(train_r2)\n",
    "\n",
    "    # Evaluation Phase\n",
    "    model.eval()\n",
    "    test_losses = []\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in test_dataloader:\n",
    "            inputs1, inputs2, targets = batch\n",
    "            input1 = inputs1[\"input_ids\"].squeeze(1).to(device)\n",
    "            attention_mask1 = inputs1[\"attention_mask\"].squeeze(1).to(device)\n",
    "            input2 = inputs2[\"input_ids\"].squeeze(1).to(device)\n",
    "            attention_mask2 = inputs2[\"attention_mask\"].squeeze(1).to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            outputs = model(input1, attention_mask1, input2, attention_mask2)\n",
    "            loss = criterion(outputs.squeeze(), targets)\n",
    "            test_losses.append(loss.item())\n",
    "            all_preds.extend(outputs.squeeze().cpu().numpy())\n",
    "            all_labels.extend(targets.cpu().numpy())\n",
    "\n",
    "    test_loss = np.mean(test_losses)\n",
    "    test_r2 = r2_score(all_labels, all_preds)\n",
    "\n",
    "    history[\"test_loss\"].append(test_loss)\n",
    "    history[\"test_r2\"].append(test_r2)\n",
    "\n",
    "    if test_r2 > history[\"max_test_r2\"]:\n",
    "        history[\"max_test_r2\"] = test_r2\n",
    "        history[\"best_preds\"] = all_preds\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Train R2: {train_r2:.4f}, Test R2: {test_r2:.4f}\")\n",
    "    torch.save(model.state_dict(), f'./models/model_epoch_{epoch + 1}.pth')\n",
    "\n",
    "# Plot Training and Validation Metrics\n",
    "# plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot Loss\n",
    "# plt.subplot(1, 2, 1)\n",
    "plt.plot(history[\"train_loss\"], label=\"Train Loss\")\n",
    "plt.plot(history[\"test_loss\"], label=\"Test Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training and Test Loss Over Epochs\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot R2 Score\n",
    "# plt.subplot(1, 2, 2)\n",
    "plt.plot(history[\"train_r2\"], label=\"Train R2\")\n",
    "plt.plot(history[\"test_r2\"], label=\"Test R2\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"R2 Score\")\n",
    "plt.title(\"Train/Test R2 Score Over Epochs\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# plt.tight_layout()\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), \"./models/final_model.pth\")\n",
    "\n",
    "# save history as pickle\n",
    "import pickle\n",
    "\n",
    "with open('./models/history.pkl', 'wb') as f:\n",
    "    pickle.dump(history, f)\n",
    "\n",
    "# last run:\n",
    "# Epoch 1/10, Train Loss: 0.2170, Test Loss: 0.1120, Test R2: 0.7158\n",
    "# Epoch 2/10, Train Loss: 0.1062, Test Loss: 0.1018, Test R2: 0.7416"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two berts + Huber loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data\n",
    "!mkdir models\n",
    "!wget --no-check-certificate 'https://drive.usercontent.google.com/download?id=1_o4xDSF6j95vAiYdd97VavyWq4EHHPdP&export=download&authuser=1&confirm=t' -O './data/dataset.csv'\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv('./data/dataset.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Suppress all FutureWarnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "def set_seed(seed: int) -> None:\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Set the seed\n",
    "SEED = 42\n",
    "set_seed(SEED)\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 16\n",
    "seq_length = 512\n",
    "hidden_size = 768  # BERT base hidden size\n",
    "mlp_hidden_size = 256\n",
    "num_epochs = 10\n",
    "learning_rate = 2e-5\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_name = \"cointegrated/LaBSE-en-ru\"\n",
    "\n",
    "\n",
    "# Dataset for dual textual features\n",
    "class DualTextDataset(Dataset):\n",
    "    def __init__(self, df, text_col_1, text_col_2, targets, tokenizer, max_len):\n",
    "        # Pre-tokenize and store inputs\n",
    "        self.tokenized_texts1 = tokenizer(df[text_col_1].tolist(), max_length=max_len, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "        self.tokenized_texts2 = tokenizer(df[text_col_2].tolist(), max_length=max_len, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "        self.targets = targets.tolist()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Return only the slice for idx\n",
    "        inputs1 = {key: val[idx] for key, val in self.tokenized_texts1.items()}\n",
    "        inputs2 = {key: val[idx] for key, val in self.tokenized_texts2.items()}\n",
    "        target = torch.tensor(self.targets[idx], dtype=torch.float)\n",
    "        return inputs1, inputs2, target\n",
    "\n",
    "# Define the dual BERT model with an MLP head\n",
    "class DualBERTWithMLP(nn.Module):\n",
    "    def __init__(self, hidden_size, mlp_hidden_size):\n",
    "        super(DualBERTWithMLP, self).__init__()\n",
    "        # Initialize two independent BERT models\n",
    "        self.bert1 = AutoModel.from_pretrained(model_name)\n",
    "        self.bert2 = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "        # Define MLP head\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(2 * hidden_size, mlp_hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(mlp_hidden_size, 1)  # Regression output\n",
    "        )\n",
    "\n",
    "    def forward(self, input1, attention_mask1, input2, attention_mask2):\n",
    "        # Forward pass through BERT1\n",
    "        cls1 = self.bert1(input_ids=input1, attention_mask=attention_mask1).last_hidden_state[:, 0, :]  # CLS token\n",
    "\n",
    "        # Forward pass through BERT2\n",
    "        cls2 = self.bert2(input_ids=input2, attention_mask=attention_mask2).last_hidden_state[:, 0, :]  # CLS token\n",
    "\n",
    "        # Concatenate CLS embeddings\n",
    "        combined_cls = torch.cat([cls1, cls2], dim=-1)  # Shape: [batch_size, 2 * hidden_size]\n",
    "\n",
    "        # Pass through MLP head\n",
    "        output = self.mlp(combined_cls)\n",
    "        return output\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Dataset and DataLoader\n",
    "# Prepare data\n",
    "text_col_1 = 'description_no_numbers_v2'\n",
    "text_col_2 = 'title_company_location_skills_source'\n",
    "X = df[[text_col_1, text_col_2]]\n",
    "y = df['log_salary_from']\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)\n",
    "\n",
    "# Make datasets\n",
    "train_dataset = DualTextDataset(X_train, text_col_1, text_col_2, y_train, tokenizer, seq_length)\n",
    "test_dataset = DualTextDataset(X_test, text_col_1, text_col_2, y_test, tokenizer, seq_length)\n",
    "# Make dataloaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Initialize the model\n",
    "model = DualBERTWithMLP(hidden_size, mlp_hidden_size)\n",
    "model = torch.nn.DataParallel(model).to(device)\n",
    "\n",
    "# Optimizer and Loss Function\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.HuberLoss()\n",
    "\n",
    "# Enhanced Training and Evaluation Loop\n",
    "history = {\"train_loss\": [],\n",
    "           \"test_loss\": [], \n",
    "           \"train_r2\": [],\n",
    "           \"test_r2\": [],\n",
    "           \"max_test_r2\": float('-inf'),\n",
    "           \"best_preds\": []\n",
    "           }\n",
    "\n",
    "test_labels = y_test\n",
    "test_preds = []\n",
    "for epoch in range(num_epochs):\n",
    "    # Training Phase\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    for batch in train_dataloader:\n",
    "        inputs1, inputs2, targets = batch\n",
    "        input1 = inputs1[\"input_ids\"].squeeze(1).to(device)\n",
    "        attention_mask1 = inputs1[\"attention_mask\"].squeeze(1).to(device)\n",
    "        input2 = inputs2[\"input_ids\"].squeeze(1).to(device)\n",
    "        attention_mask2 = inputs2[\"attention_mask\"].squeeze(1).to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input1, attention_mask1, input2, attention_mask2)\n",
    "        loss = criterion(outputs.squeeze(), targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_losses.append(loss.item())\n",
    "        all_preds.extend(outputs.squeeze().cpu().detach().numpy())\n",
    "        all_labels.extend(targets.cpu().numpy())\n",
    "\n",
    "    train_loss = np.mean(train_losses)\n",
    "    train_r2 = r2_score(all_labels, all_preds)\n",
    "    history[\"train_loss\"].append(train_loss)\n",
    "    history[\"train_r2\"].append(train_r2)\n",
    "\n",
    "    # Evaluation Phase\n",
    "    model.eval()\n",
    "    test_losses = []\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in test_dataloader:\n",
    "            inputs1, inputs2, targets = batch\n",
    "            input1 = inputs1[\"input_ids\"].squeeze(1).to(device)\n",
    "            attention_mask1 = inputs1[\"attention_mask\"].squeeze(1).to(device)\n",
    "            input2 = inputs2[\"input_ids\"].squeeze(1).to(device)\n",
    "            attention_mask2 = inputs2[\"attention_mask\"].squeeze(1).to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            outputs = model(input1, attention_mask1, input2, attention_mask2)\n",
    "            loss = criterion(outputs.squeeze(), targets)\n",
    "            test_losses.append(loss.item())\n",
    "            all_preds.extend(outputs.squeeze().cpu().numpy())\n",
    "            all_labels.extend(targets.cpu().numpy())\n",
    "\n",
    "    test_loss = np.mean(test_losses)\n",
    "    test_r2 = r2_score(all_labels, all_preds)\n",
    "\n",
    "    history[\"test_loss\"].append(test_loss)\n",
    "    history[\"test_r2\"].append(test_r2)\n",
    "\n",
    "    if test_r2 > history[\"max_test_r2\"]:\n",
    "        history[\"max_test_r2\"] = test_r2\n",
    "        history[\"best_preds\"] = all_preds\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Train R2: {train_r2:.4f}, Test R2: {test_r2:.4f}\")\n",
    "    torch.save(model.state_dict(), f'./models/model_epoch_{epoch + 1}.pth')\n",
    "\n",
    "# Plot Training and Validation Metrics\n",
    "# plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot Loss\n",
    "# plt.subplot(1, 2, 1)\n",
    "plt.plot(history[\"train_loss\"], label=\"Train Loss\")\n",
    "plt.plot(history[\"test_loss\"], label=\"Test Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training and Test Loss Over Epochs\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot R2 Score\n",
    "# plt.subplot(1, 2, 2)\n",
    "plt.plot(history[\"train_r2\"], label=\"Train R2\")\n",
    "plt.plot(history[\"test_r2\"], label=\"Test R2\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"R2 Score\")\n",
    "plt.title(\"Train/Test R2 Score Over Epochs\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# plt.tight_layout()\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), \"./models/final_model.pth\")\n",
    "\n",
    "# save history as pickle\n",
    "import pickle\n",
    "\n",
    "with open('./models/history.pkl', 'wb') as f:\n",
    "    pickle.dump(history, f)\n",
    "\n",
    "# last run:\n",
    "# Epoch 1/10, Train Loss: 0.2170, Test Loss: 0.1120, Test R2: 0.7158\n",
    "# Epoch 2/10, Train Loss: 0.1062, Test Loss: 0.1018, Test R2: 0.7416"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two berts + Mean pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data\n",
    "!mkdir models\n",
    "!wget --no-check-certificate 'https://drive.usercontent.google.com/download?id=1_o4xDSF6j95vAiYdd97VavyWq4EHHPdP&export=download&authuser=1&confirm=t' -O './data/dataset.csv'\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv('./data/dataset.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Suppress all FutureWarnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "def set_seed(seed: int) -> None:\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Set the seed\n",
    "SEED = 42\n",
    "set_seed(SEED)\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 16\n",
    "seq_length = 512\n",
    "hidden_size = 768  # BERT base hidden size\n",
    "mlp_hidden_size = 256\n",
    "num_epochs = 10\n",
    "learning_rate = 2e-5\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_name = \"cointegrated/LaBSE-en-ru\"\n",
    "\n",
    "# Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0]  # First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    return sum_embeddings / sum_mask\n",
    "\n",
    "\n",
    "# Dataset for dual textual features\n",
    "class DualTextDataset(Dataset):\n",
    "    def __init__(self, df, text_col_1, text_col_2, targets, tokenizer, max_len):\n",
    "        # Pre-tokenize and store inputs\n",
    "        self.tokenized_texts1 = tokenizer(df[text_col_1].tolist(), max_length=max_len, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "        self.tokenized_texts2 = tokenizer(df[text_col_2].tolist(), max_length=max_len, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "        self.targets = targets.tolist()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Return only the slice for idx\n",
    "        inputs1 = {key: val[idx] for key, val in self.tokenized_texts1.items()}\n",
    "        inputs2 = {key: val[idx] for key, val in self.tokenized_texts2.items()}\n",
    "        target = torch.tensor(self.targets[idx], dtype=torch.float)\n",
    "        return inputs1, inputs2, target\n",
    "\n",
    "# Define the dual BERT model with an MLP head\n",
    "class DualBERTWithMLP(nn.Module):\n",
    "    def __init__(self, hidden_size, mlp_hidden_size):\n",
    "        super(DualBERTWithMLP, self).__init__()\n",
    "        # Initialize two independent BERT models\n",
    "        self.bert1 = AutoModel.from_pretrained(model_name)\n",
    "        self.bert2 = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "        # Define MLP head\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(2 * hidden_size, mlp_hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(mlp_hidden_size, 1)  # Regression output\n",
    "        )\n",
    "\n",
    "    def forward(self, input1, attention_mask1, input2, attention_mask2):\n",
    "        # Forward pass through BERT1\n",
    "        output1 = self.bert1(input_ids=input1, attention_mask=attention_mask1)\n",
    "        mean_embedding_1 = mean_pooling(output1, attention_mask1)\n",
    "\n",
    "        # Forward pass through BERT1\n",
    "        output2 = self.bert2(input_ids=input2, attention_mask=attention_mask2)\n",
    "        mean_embedding_2 = mean_pooling(output2, attention_mask2)\n",
    "\n",
    "\n",
    "        # Concatenate mean embeddings\n",
    "        combined_mean_embeddings = torch.cat([mean_embedding_1, mean_embedding_2], dim=-1)  # Shape: [batch_size, 2 * hidden_size]\n",
    "\n",
    "        # Pass through MLP head\n",
    "        output = self.mlp(combined_mean_embeddings)\n",
    "        return output\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Dataset and DataLoader\n",
    "# Prepare data\n",
    "text_col_1 = 'description_no_numbers_v2'\n",
    "text_col_2 = 'title_company_location_skills_source'\n",
    "X = df[[text_col_1, text_col_2]]\n",
    "y = df['log_salary_from']\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)\n",
    "\n",
    "# Make datasets\n",
    "train_dataset = DualTextDataset(X_train, text_col_1, text_col_2, y_train, tokenizer, seq_length)\n",
    "test_dataset = DualTextDataset(X_test, text_col_1, text_col_2, y_test, tokenizer, seq_length)\n",
    "# Make dataloaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Initialize the model\n",
    "model = DualBERTWithMLP(hidden_size, mlp_hidden_size)\n",
    "model = torch.nn.DataParallel(model).to(device)\n",
    "\n",
    "# Optimizer and Loss Function\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.MSELoss()  # For regression\n",
    "\n",
    "# Enhanced Training and Evaluation Loop\n",
    "history = {\"train_loss\": [],\n",
    "           \"test_loss\": [], \n",
    "           \"train_r2\": [],\n",
    "           \"test_r2\": [],\n",
    "           \"max_test_r2\": float('-inf'),\n",
    "           \"best_preds\": []\n",
    "           }\n",
    "\n",
    "test_labels = y_test\n",
    "test_preds = []\n",
    "for epoch in range(num_epochs):\n",
    "    # Training Phase\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    for batch in train_dataloader:\n",
    "        inputs1, inputs2, targets = batch\n",
    "        input1 = inputs1[\"input_ids\"].squeeze(1).to(device)\n",
    "        attention_mask1 = inputs1[\"attention_mask\"].squeeze(1).to(device)\n",
    "        input2 = inputs2[\"input_ids\"].squeeze(1).to(device)\n",
    "        attention_mask2 = inputs2[\"attention_mask\"].squeeze(1).to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input1, attention_mask1, input2, attention_mask2)\n",
    "        loss = criterion(outputs.squeeze(), targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_losses.append(loss.item())\n",
    "        all_preds.extend(outputs.squeeze().cpu().detach().numpy())\n",
    "        all_labels.extend(targets.cpu().numpy())\n",
    "\n",
    "    train_loss = np.mean(train_losses)\n",
    "    train_r2 = r2_score(all_labels, all_preds)\n",
    "    history[\"train_loss\"].append(train_loss)\n",
    "    history[\"train_r2\"].append(train_r2)\n",
    "\n",
    "    # Evaluation Phase\n",
    "    model.eval()\n",
    "    test_losses = []\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in test_dataloader:\n",
    "            inputs1, inputs2, targets = batch\n",
    "            input1 = inputs1[\"input_ids\"].squeeze(1).to(device)\n",
    "            attention_mask1 = inputs1[\"attention_mask\"].squeeze(1).to(device)\n",
    "            input2 = inputs2[\"input_ids\"].squeeze(1).to(device)\n",
    "            attention_mask2 = inputs2[\"attention_mask\"].squeeze(1).to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            outputs = model(input1, attention_mask1, input2, attention_mask2)\n",
    "            loss = criterion(outputs.squeeze(), targets)\n",
    "            test_losses.append(loss.item())\n",
    "            all_preds.extend(outputs.squeeze().cpu().numpy())\n",
    "            all_labels.extend(targets.cpu().numpy())\n",
    "\n",
    "    test_loss = np.mean(test_losses)\n",
    "    test_r2 = r2_score(all_labels, all_preds)\n",
    "\n",
    "    history[\"test_loss\"].append(test_loss)\n",
    "    history[\"test_r2\"].append(test_r2)\n",
    "\n",
    "    if test_r2 > history[\"max_test_r2\"]:\n",
    "        history[\"max_test_r2\"] = test_r2\n",
    "        history[\"best_preds\"] = all_preds\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Train R2: {train_r2:.4f}, Test R2: {test_r2:.4f}\")\n",
    "    torch.save(model.state_dict(), f'./models/model_epoch_{epoch + 1}.pth')\n",
    "\n",
    "# Plot Training and Validation Metrics\n",
    "# plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot Loss\n",
    "# plt.subplot(1, 2, 1)\n",
    "plt.plot(history[\"train_loss\"], label=\"Train Loss\")\n",
    "plt.plot(history[\"test_loss\"], label=\"Test Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training and Test Loss Over Epochs\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot R2 Score\n",
    "# plt.subplot(1, 2, 2)\n",
    "plt.plot(history[\"train_r2\"], label=\"Train R2\")\n",
    "plt.plot(history[\"test_r2\"], label=\"Test R2\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"R2 Score\")\n",
    "plt.title(\"Train/Test R2 Score Over Epochs\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# plt.tight_layout()\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), \"./models/final_model.pth\")\n",
    "\n",
    "# save history as pickle\n",
    "import pickle\n",
    "\n",
    "with open('./models/history.pkl', 'wb') as f:\n",
    "    pickle.dump(history, f)\n",
    "\n",
    "# last run:\n",
    "# Epoch 1/10, Train Loss: 0.2170, Test Loss: 0.1120, Test R2: 0.7158\n",
    "# Epoch 2/10, Train Loss: 0.1062, Test Loss: 0.1018, Test R2: 0.7416"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression on the [MASK] token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSDAE "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ods-final-project-salary",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
