x-airflow-common: &airflow-common
  build:
    context: .
    dockerfile: backend/docker/airflow/Dockerfile
  env_file:
    - .env
  environment:
    - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/airflow
    - AIRFLOW__CORE__EXECUTOR=LocalExecutor
    - AIRFLOW__CORE__FERNET_KEY=${FERNET_KEY}
    - AIRFLOW__CORE__LOAD_EXAMPLES=False
    - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=True
    - AIRFLOW__CORE__ENABLE_XCOM_PICKLING=True
    - AIRFLOW_HOME=/opt/airflow
    - AIRFLOW__SCHEDULER__DAG_DIR_LIST_INTERVAL=30
    - AIRFLOW__CORE__DAGS_FOLDER=/opt/airflow/dags
    - AWS_ALLOW_HTTP=true
  volumes:
    - ./dags:/opt/airflow/dags
    - ./logs:/opt/airflow/logs
    - ./plugins:/opt/airflow/plugins
    - airflow-repo:/opt/airflow/repo
    - ~/.aws:/home/airflow/.aws:ro
    - /var/run/docker.sock:/var/run/docker.sock:rw  # Add read-write permissions
  depends_on:
    postgres:
      condition: service_healthy
  user: "50000:999"  # Use root group (usually docker group is 999)
  group_add:
    - "999"  # Add docker group to the container

services:
  postgres:
    image: postgres:13
    container_name: postgres
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=airflow
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "airflow"]
      interval: 5s
      timeout: 5s
      retries: 5
    volumes:
      - postgres-db-volume:/var/lib/postgresql/data

  # service to init Airflow DB and create admin
  airflow-init:
    <<: *airflow-common
    container_name: airflow-init
    command: >
      bash -c '
        airflow db init && airflow users create --username admin --password admin --firstname Anonymous --lastname Admin --role Admin --email admin@example.com
      '
    depends_on:
      postgres:
        condition: service_healthy

  repo-init:
    container_name: repo-init
    build:
      context: .
      dockerfile: backend/docker/repo-init/Dockerfile
    volumes:
      - airflow-repo:/opt/airflow/repo
    depends_on:
      postgres:
        condition: service_healthy

  webserver:
    <<: *airflow-common
    container_name: webserver
    user: "50000:999" # Ensure airflow user has correct permissions
    command: >
        bash -c "
        cd /opt/airflow/repo && \
        airflow db init && \
        airflow db upgrade && \
        airflow webserver
        "
    ports:
      - "127.0.0.1:8080:8080"
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 10s
      timeout: 10s
      retries: 5
    depends_on:
      repo-init:
        condition: service_completed_successfully
      airflow-init:
        condition: service_completed_successfully
      postgres:
        condition: service_healthy

  scheduler:
    <<: *airflow-common
    container_name: scheduler
    user: "50000:0" # Ensure airflow user has correct permissions
    command: airflow scheduler
    depends_on:
      airflow-init:
        condition: service_started
      webserver:
        condition: service_started

  mlflow:
    container_name: mlflow
    build:
      context: .
      dockerfile: backend/docker/mlflow/Dockerfile
    env_file:
      - .env
    ports:
      - "127.0.0.1:5000:5000"
    environment:
      - MLFLOW_S3_IGNORE_TLS=true
      - ARTIFACT_ROOT=s3://mlflow-artifacts/
      - MLFLOW_BUCKET_NAME=mlflow-artifacts
      - MLFLOW_DEFAULT_ARTIFACT_ROOT=s3://mlflow-artifacts/
      - MLFLOW_S3_UPLOAD_EXTRA_ARGS='{"ACL":"bucket-owner-full-control"}'
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:5000/health"]
      interval: 10s
      timeout: 10s
      retries: 3
    depends_on:
      minio:
        condition: service_healthy

  minio:
    image: minio/minio
    container_name: minio-minio
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      - MINIO_ROOT_USER=${AWS_ACCESS_KEY_ID}
      - MINIO_ROOT_PASSWORD=${AWS_SECRET_ACCESS_KEY}
    command: server /data --console-address ":9001"
    volumes:
      - minio-data:/data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3

  mc:  # Add MinIO client to create initial bucket
    image: minio/mc
    container_name: minio-mc
    depends_on:
      minio:
        condition: service_healthy
    entrypoint: >
      /bin/sh -c "
      /usr/bin/mc alias set myminio http://minio:9000 ${AWS_ACCESS_KEY_ID} ${AWS_SECRET_ACCESS_KEY};
      /usr/bin/mc mb myminio/mlflow-artifacts || true;
      /usr/bin/mc anonymous set public myminio/mlflow-artifacts;
      exit 0;
      "

  streamlit:
    container_name: streamlit
    build:
      context: .
      dockerfile: backend/docker/streamlit/Dockerfile
    env_file:
      - .env
    ports:
      - "8501:8501"
    restart: always
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8501/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    depends_on:
      mlflow:
        condition: service_healthy

  fastapi:
    container_name: fastapi
    build:
      context: .
      dockerfile: backend/docker/fastapi/Dockerfile
    env_file:
      - .env
    ports:
      - "8000:8000"
    restart: always
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/healthcheck"]
      interval: 120s
      timeout: 5s
      retries: 5
      start_period: 20s

  prometheus:
    container_name: prometheus
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
    depends_on:
      fastapi:
        condition: service_started
    restart: always

  grafana:
    container_name: grafana
    build:
      context: .
      dockerfile: backend/docker/grafana/Dockerfile
    ports:
      - "3000:3000"
    environment:
      GF_INSTALL_PLUGINS: "grafana-clock-panel,grafana-simple-json-datasource"
      GF_SECURITY_ADMIN_USER: admin
      GF_SECURITY_ADMIN_PASSWORD: admin
      GF_DASHBOARDS_MIN_REFRESH_INTERVAL: 5s
      GF_PLUGINS_ALLOW_LOADING_UNSIGNED_PLUGINS: "grafana-pyroscope-app,grafana-lokiexplore-app"
    volumes:
      - ./grafana/provisioning/dashboards/salary-prediction.json:/etc/grafana/provisioning/dashboards/salary-prediction.json:ro
    depends_on:
      prometheus:
        condition: service_started
    restart: always

volumes:
  postgres-db-volume:
  airflow-repo:
  minio-data:
